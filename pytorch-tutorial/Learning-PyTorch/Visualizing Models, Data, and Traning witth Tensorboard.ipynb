{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Models, Data and Traning with Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll learn how to:\n",
    "\n",
    "1. Read in data and with appropriate transforms\n",
    "2. Set up TensorBoard\n",
    "3. Write to TensorBoard\n",
    "4. Inspect a model architecutre using TensorBoard\n",
    "5. Use TensorBoard to create interactive versions of the visualizations we created in last tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specially, on point 5, we'll see:\n",
    "\n",
    "* A couple of ways to insepect our training data\n",
    "* How to track our model's performance as it trains\n",
    "* How to assess our model's performance once it is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "\n",
    "# dataset\n",
    "trainset = torchvision.datasets.FashionMNIST(\n",
    "    './data', download=True, train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(\n",
    "    './data', download=True, train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                         shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "        \n",
    "    img = img / 2 +  0.5  # unnormlize\n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap='Greys')\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a similar model architecutre from that tutorial, making only minor modifications to account for the fact that the images are now one channel instead of three and 28*28 instead of 32*32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define the same `optimizer` and `criterion` from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBord setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll set up TensorBoard, importing `tensorboard` from `torch.utils` and defining a `SummaryWriter`, our key object for writing information to TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pytorch.org/tutorials/_static/img/tensorboard_first_view.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the model using TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of TensorBoad's strenghts is its ability to visualize model structures. Let's visualize the model we built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pytorch.org/tutorials/_static/img/tensorboard_model_viz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and double click on `Net` to see it expand, seeing a detailed view of the individual operations that make up the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a \"Projector\" to TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the lower dimensional representation of higher  dimensional data via the `add_embedding` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core._api.v2.io.gfile' has no attribute 'get_filesystem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-a38524f822fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m writer.add_embedding(features,\n\u001b[1;32m     20\u001b[0m                     \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                     label_img=images.unsqueeze(1))\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_embedding\u001b[0;34m(self, mat, metadata, label_img, global_step, tag, metadata_header)\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.io.gfile' has no attribute 'get_filesystem'"
     ]
    }
   ],
   "source": [
    "def select_n_random(data, labels, n=100):\n",
    "    \"\"\"\n",
    "    Select n random datapoints and their corresponding lables from\n",
    "    a dataset.\n",
    "    \"\"\"\n",
    "    assert len(data) == len(labels)\n",
    "    \n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random iamges and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embedding\n",
    "features = images.view(-1, 28*28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 28, 28]), torch.Size([100]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking model training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    \"\"\"\n",
    "    Generates predictions adn corresonding probabilities from a\n",
    "    trained network and a list of images.\n",
    "    \"\"\"\n",
    "    output = net(images)\n",
    "    # convert output probilities to predicted class\n",
    "    _, pred_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(pred_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    \"\"\"\n",
    "    Generates matplotlib Figure using a trained network, along with\n",
    "    images and labels from a batch, that shows the network's top \n",
    "    prediction along with its probability, alongnside the actual\n",
    "    label, coloring this information based on wheterh the prediction\n",
    "    was correct or not.\n",
    "    Uses the \"iamgess_to_probs\" function.\n",
    "    \"\"\"\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    \n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "\n",
    "for epoch in range(1):\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            \n",
    "            # get the inputs, data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outpus = net(inputs)\n",
    "            loss = criterion(outpus, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i % 1000 == 99:\n",
    "                # log the running loss\n",
    "                writer.add_scalar('training loass',\n",
    "                                 running_loss / 1000,\n",
    "                                 epoch * len(trainloader) + i)\n",
    "                \n",
    "                writer.add_figure('predictions vs. actuals',\n",
    "                                 plot_classes_preds(net, inputs, labels),\n",
    "                                 global_step=epoch*len(trainloader) + i)\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                \n",
    "print('Finishing Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
