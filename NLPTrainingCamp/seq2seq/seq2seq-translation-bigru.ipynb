{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq模型——机器翻译\n",
    "\n",
    "初级改进：\n",
    "\n",
    "1. 用GRU替换RNN\n",
    "2. 使用双向的GRU\n",
    "3. 超参调优\n",
    "4. 引入更多的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果使用GPU，则将下面的变量设为`True`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "print('CUDA available: %s' % torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "print('Device: %s' % device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据\n",
    "\n",
    "我们将读取目录下的`cn-eng.txt`文件，其中每一行是一个平行句对，例子如下：\n",
    "\n",
    "```\n",
    "我很冷。    I am cold.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对于单词进行编号\n",
    "\n",
    "这里引入了两个特殊符号，“SOS”即“Start of sentence”和“EOS”即“End of sentence”。他们会加到输入文本的两端，以控制解码过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang(object):\n",
    "    \"\"\"\n",
    "    词表Vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        if self.name == 'cn':    \n",
    "            for word in sentence:\n",
    "                self.index_word(word)\n",
    "        else:\n",
    "            for word in sentence.split(' '):\n",
    "                self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本预处理\n",
    "\n",
    "丢弃除了中文、字母和常用标点之外的符号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5.!?，。？]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取平行语料，并进行清理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    \"\"\"\n",
    "    读取语料数据.\n",
    "    :return (输入词表，输出词表，平行语料对)\n",
    "    \"\"\"\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('%s-%s.txt' % (lang1, lang2)).read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过滤句子\n",
    "\n",
    "样例为了加快训练，只保留了不长于10个单词的句对，真正实验中将更多数据考虑进来可能获得更好的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理数据的全过程：\n",
    "\n",
    "- 读取数据，每一行分别处理，将其转换成句对\n",
    "- 对于文本进行处理，过滤无用符号\n",
    "- 根据已有文本对于单词进行编号，构建符号到编号的映射\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 90000 sentence pairs\n",
      "Trimmed to 68898 sentence pairs\n",
      "Indexing words...\n",
      "['湯姆在他的桌邊工作。', 'tom sat at his desk working .']\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('cn', 'eng', False)\n",
    "\n",
    "# Print an example pair\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将文本数据转换为张量\n",
    "\n",
    "为了训练，我们需要将句子变成神经网络可以理解的东西（数字）。每个句子将被分解成单词，然后变成张量，其中每个单词都被索引替换（来自之前的Lang索引）。在创建这些张量时，我们还将附加EOS令牌以表示该句子已结束。\n",
    "\n",
    "![](https://i.imgur.com/LzocpGH.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    根据词表，将句子转化成索引列表。\n",
    "\n",
    "    :reutrn list，e.g. [1, 2, 3, 4]\n",
    "    \"\"\"\n",
    "    if lang.name == 'cn':\n",
    "        return [lang.word2index[word] for word in sentence]\n",
    "    else:\n",
    "        return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    将句子转换成Tensor.\n",
    "    \n",
    "    :return Tensor, shape(n, 1)\n",
    "    \"\"\"\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = torch.LongTensor(indexes).view(-1, 1)\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    \"\"\"\n",
    "    将平行语料对转化成Tensors.\n",
    "    \n",
    "    :return (input_tensor, output_tensor)\n",
    "    \"\"\"\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    target_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair: ['她和我同班。', 'she and i are in the same class .']\n",
      "input_tensor shape: torch.Size([7, 1]), output_tensor shap: torch.Size([10, 1])\n",
      "input_tensor: tensor([[202],\n",
      "        [331],\n",
      "        [  2],\n",
      "        [520],\n",
      "        [954],\n",
      "        [ 12],\n",
      "        [  1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "print('pair: %s' % pair)\n",
    "\n",
    "input_tensor, target_tensor = variables_from_pair(pair)\n",
    "print('input_tensor shape: %s, output_tensor shap: %s' % (input_tensor.shape, target_tensor.shape))\n",
    "print('input_tensor: %s' % input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class EncoderGRU(nn.Module):\n",
    "    \"\"\"GRU 编码器\"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, bidirectional=False):\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        :param input_size, 输入词表大\n",
    "        :param hidden_size, Embedding维度大小，RNN hidden大小\n",
    "        :param n_layers, RNN层数\n",
    "        \"\"\"\n",
    "        super(EncoderGRU, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        # 用GRU替换RNN\n",
    "        # self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param word_inputs, 输入序列 shape(n, 1)\n",
    "        :param hidden, 隐层 shape(seq_len*n_layers, batch_size, hidden_size)\n",
    "        :return output(seq_len, batch, num_directions*hidden_size),\n",
    "                hidden(num_layers*num_directions, hidden_size)\n",
    "        \"\"\"\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        num_directions = 2 if self.bidirectional else 1\n",
    "        hidden = torch.zeros(self.n_layers*num_directions, 1, self.hidden_size)\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len: 9, encoder_output shape: torch.Size([10, 1, 200]), encoder_hidden shape: torch.Size([2, 1, 100])\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderGRU(input_lang.n_words, 100, bidirectional=True)\n",
    "encoder.to(device)\n",
    "\n",
    "pair = random.choice(pairs)\n",
    "\n",
    "encoder_hidden = encoder.init_hidden()\n",
    "encoder_output, encoder_hidden = encoder(variable_from_sentence(input_lang, pair[0]), encoder_hidden)\n",
    "print('seq_len: %s, encoder_output shape: %s, encoder_hidden shape: %s' % (\n",
    "    len(pair[0]), encoder_output.shape, encoder_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DecoderGRU(nn.Module):\n",
    "    \"\"\"GRU 解码器\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(DecoderGRU, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "\n",
    "        # 使用GRU替换RNN\n",
    "        # self.rnn = nn.RNN(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden):\n",
    "        # Note: we run this one step at a time        \n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        rnn_output, hidden = self.rnn(word_embedded, last_hidden)\n",
    "\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        output = F.log_softmax(self.out(rnn_output))\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output shape: torch.Size([1, 8947]), decoder_hidden shape: torch.Size([1, 1, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "decoder = DecoderGRU(200, output_lang.n_words)\n",
    "decoder.to(device)\n",
    "\n",
    "decoder_hidden = encoder_hidden.view(1, 1, -1)\n",
    "decoer_output, decoder_hidden = decoder(variable_from_sentence(output_lang, pair[1])[0], decoder_hidden)\n",
    "print('decoder_output shape: %s, decoder_hidden shape: %s' % (decoer_output.shape, decoder_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "为了训练，我们首先通过编码器逐字运行输入语句，并跟踪每个输出和最新的隐藏状态。接下来，为解码器提供解码器的最后一个隐藏状态作为其第一隐藏状态，并向其提供`<SOS>`作为其第一输入。从那里开始，我们迭代地预测来自解码器的下一个单词。\n",
    "    \n",
    "**Teacher Forcing 和 Scheduled Sampling**\n",
    "\n",
    "\"Teacher Forcing\"指的是每次都基于完全准确的上文进行解码，这样训练模型收敛很快，但是会造成实际场景和训练场景有较大差别，因为实际场景上文也都是模型预测的，可能不准确，具体细节可参考[论文](http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf)。\n",
    "\n",
    "观察Teacher Forcing的网络的输出，我们可以看到该网络语法连贯，但是偏离正确的翻译。可以将其为学会了如何听老师的指示，而未学习如何独自冒险。\n",
    "\n",
    "解决强迫教师问题的方法称为“计划抽样”（[Scheduled Sampling](https://arxiv.org/abs/1506.03099)），它在训练时仅在使用目标值和预测值之间进行切换。我们将在训练时随机选择,有时我们将使用真实目标作为输入（忽略解码器的输出），有时我们将使用解码器的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, \n",
    "          encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, \n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = torch.LongTensor([[SOS_token]])\n",
    "    # Use last hidden state from encoder to start decoder\n",
    "    decoder_hidden = encoder_hidden.view(encoder.n_layers, encoder_hidden.shape[1], -1)\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = torch.LongTensor([[ni]]) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是用于辅助输出训练情况的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行训练GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:57: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:58: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/50000, 0m 16s (- 13m 37s), 4.8753\n",
      "Epoch 2000/50000, 0m 34s (- 13m 37s), 4.4905\n",
      "Epoch 3000/50000, 0m 51s (- 13m 25s), 4.3325\n",
      "Epoch 4000/50000, 1m 9s (- 13m 13s), 4.1923\n",
      "Epoch 5000/50000, 1m 26s (- 12m 58s), 4.1441\n",
      "Epoch 6000/50000, 1m 44s (- 12m 44s), 3.9944\n",
      "Epoch 7000/50000, 2m 11s (- 13m 26s), 3.9190\n",
      "Epoch 8000/50000, 2m 40s (- 14m 1s), 3.8008\n",
      "Epoch 9000/50000, 3m 9s (- 14m 22s), 3.8251\n",
      "Epoch 10000/50000, 3m 38s (- 14m 33s), 3.6677\n",
      "Epoch 11000/50000, 4m 7s (- 14m 37s), 3.7228\n",
      "Epoch 12000/50000, 4m 36s (- 14m 34s), 3.5444\n",
      "Epoch 13000/50000, 5m 5s (- 14m 30s), 3.5545\n",
      "Epoch 14000/50000, 5m 35s (- 14m 21s), 3.4658\n",
      "Epoch 15000/50000, 6m 3s (- 14m 8s), 3.4211\n",
      "Epoch 16000/50000, 6m 32s (- 13m 54s), 3.3751\n",
      "Epoch 17000/50000, 7m 1s (- 13m 38s), 3.3537\n",
      "Epoch 18000/50000, 7m 30s (- 13m 21s), 3.3143\n",
      "Epoch 19000/50000, 7m 59s (- 13m 2s), 3.2197\n",
      "Epoch 20000/50000, 8m 28s (- 12m 43s), 3.2751\n",
      "Epoch 21000/50000, 8m 57s (- 12m 22s), 3.1798\n",
      "Epoch 22000/50000, 9m 27s (- 12m 1s), 3.1666\n",
      "Epoch 23000/50000, 9m 56s (- 11m 39s), 3.0633\n",
      "Epoch 24000/50000, 10m 25s (- 11m 18s), 3.1003\n",
      "Epoch 25000/50000, 10m 55s (- 10m 55s), 3.0510\n",
      "Epoch 26000/50000, 11m 24s (- 10m 32s), 3.0095\n",
      "Epoch 27000/50000, 11m 54s (- 10m 8s), 3.0557\n",
      "Epoch 28000/50000, 12m 23s (- 9m 44s), 3.0219\n",
      "Epoch 29000/50000, 12m 53s (- 9m 19s), 2.9144\n",
      "Epoch 30000/50000, 13m 22s (- 8m 55s), 2.8305\n",
      "Epoch 31000/50000, 13m 52s (- 8m 30s), 2.8825\n",
      "Epoch 32000/50000, 14m 21s (- 8m 4s), 2.8379\n",
      "Epoch 33000/50000, 14m 51s (- 7m 39s), 2.8578\n",
      "Epoch 34000/50000, 15m 20s (- 7m 13s), 2.8108\n",
      "Epoch 35000/50000, 15m 50s (- 6m 47s), 2.6812\n",
      "Epoch 36000/50000, 16m 19s (- 6m 21s), 2.7422\n",
      "Epoch 37000/50000, 16m 49s (- 5m 54s), 2.7137\n",
      "Epoch 38000/50000, 17m 18s (- 5m 28s), 2.7492\n",
      "Epoch 39000/50000, 17m 48s (- 5m 1s), 2.6077\n",
      "Epoch 40000/50000, 18m 17s (- 4m 34s), 2.6816\n",
      "Epoch 41000/50000, 18m 46s (- 4m 7s), 2.6642\n",
      "Epoch 42000/50000, 19m 16s (- 3m 40s), 2.6279\n",
      "Epoch 43000/50000, 19m 44s (- 3m 12s), 2.5245\n",
      "Epoch 44000/50000, 20m 14s (- 2m 45s), 2.6067\n",
      "Epoch 45000/50000, 20m 43s (- 2m 18s), 2.5418\n",
      "Epoch 46000/50000, 21m 12s (- 1m 50s), 2.3854\n",
      "Epoch 47000/50000, 21m 41s (- 1m 23s), 2.5778\n",
      "Epoch 48000/50000, 22m 10s (- 0m 55s), 2.4911\n",
      "Epoch 49000/50000, 22m 40s (- 0m 27s), 2.4203\n",
      "Epoch 50000/50000, 23m 9s (- 0m 0s), 2.4277\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout_p = 0.05\n",
    "bidirectional = True\n",
    "n_epochs = 50000\n",
    "decoder_hidden_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderGRU(input_lang.n_words, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "decoder = DecoderGRU(decoder_hidden_size, output_lang.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Configuring training\n",
    "plot_every = 200\n",
    "print_every = 1000\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every\n",
    "\n",
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    training_pair = variables_from_pair(random.choice(pairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, encoder, decoder, \n",
    "                 encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = 'Epoch %d/%d, %s, %.4f' % (epoch, n_epochs, time_since(start, epoch / n_epochs), \n",
    "                                                   print_loss_avg)\n",
    "        print(print_summary)\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**绘制训练loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABCZklEQVR4nO3deXxddZ34/9f7btn3vU3SdE03uqYLlKXsFBfUARUVBGUQZRx/31EHHB1HxxlHB1eGQaYDiiuOCgiibLJvpbR0b+neplmbfc9NbvL5/XHOublJbtpbetI0yfv5ePTR5N6Tcz+nF973k/d5f94fMcaglFJq/POM9QCUUkq5QwO6UkpNEBrQlVJqgtCArpRSE4QGdKWUmiB8Y/XC2dnZpqSkZKxeXimlxqXNmzfXG2Nyoj03ZgG9pKSETZs2jdXLK6XUuCQiR0d6TlMuSik1QWhAV0qpCSKmlIuIHAHagD4gZIwpi3LMWuBHgB+oN8Zc5NYglVJKndyp5NAvNsbUR3tCRNKBe4GrjDHlIpLrxuCUUkrFzq2Uy8eAR4wx5QDGmOMunVcppVSMYg3oBnhGRDaLyK1Rnp8DZIjIi/YxN0Y7iYjcKiKbRGRTXV3dux2zUkqpKGJNuawxxlTZqZRnReQdY8zLQ86zHLgUSADeEJENxph9kScxxqwH1gOUlZVpm0ellHJRTDN0Y0yV/fdx4FFg5ZBDKoCnjDEddp79ZWCxmwN17K1p4/vP7KWhPTgap1dKqXHrpAFdRJJEJMX5GrgC2DnksMeAC0TEJyKJwCpgj9uDBThU185/PX+A+vae0Ti9UkqNW7GkXPKAR0XEOf43xpinROQ2AGPMfcaYPSLyFLAd6AfuN8YMDfquCPisz6BgqG80Tq+UUuPWSQO6MeYQUdInxpj7hnx/F3CXe0OLLs7nBSAY6h/tl1JKqXFl3K0UdWboPRrQlVJqkHEX0OM05aKUUlGNu4CuM3SllIoupoAuIkdEZIeIbBWREXveisgKEekTkWvdG+JgAzN0DehKKRXJlV4uACLiBb4LPH3aozqBgAZ0pZSKys2Uy+eBh4FR7eOiVS5KKRWdK71cRGQq8EHgvmE/Ofi40+7lojl0pZSKLtaAvsYYswxYB9wuIhcOef5HwB3GmBOWnhhj1htjyowxZTk5UbfEOymtclFKqehiyqFH9nIREaeXS2RzrjLgt/Zq0mzgahEJGWP+6O5wIeDVGbpSSkVz0oBu92/xGGPaInq5/GvkMcaY6RHHPwg8MRrBHMDjEQJej+bQlVJqCFd6uYzi+KIK+Dw6Q1dKqSFc6+US8fhNpz+sE4vzeTSHrpRSQ4y7laKgM3SllIpmXAZ0a4auAV0ppSKNy4Ae8HkI9mpAV0qpSDGVLYrIEaAN6ANCxpiyIc9/HLjD/rYd+KwxZpuL4xwkzuelp08DulJKRXKrl8th4CJjTJOIrMPaCHrVaY9uBAG9KaqUUsOcSkAfkTHm9YhvNwCFbpx3JHF6U1QppYZxpZfLEJ8Gnoz2hBu9XMCZoWtAV0qpSLHO0NcYY6pEJBd4VkTeMca8PPQgEbkYK6CfH+0kxpj1WOkYysrKzLscs87QlVIqiphm6JG9XACnl8sgIrIIuB+4xhjT4OYghwr4vDpDV0qpIU4a0EUkSURSnK+xernsHHJMMfAIcIMxZt9oDDSSztCVUmo4t3q5fB3IAu61jxtW2ugmrXJRSqnhXOnlYoy5BbjF3aGNTFeKKqXUcON3pagGdKWUGmRcBvQ4n5eeUD/GvOtCGaWUmnDGaUC3dy3S5f9KKRUWU0AXkSMiskNEtorIpijPi4jcLSIHRGS7iCxzf6gD4nSjaKWUGsatXi7rgNn2n1XATxjlXi4AwVA/KaP1IkopNc64lXK5BviFsWwA0kWkwKVzD6MzdKWUGs6tXi5TgWMR31fYjw3iZi8XQCtdlFIqQqwBfY0xZhlWauV2EblwyPMS5WeGlaAYY9YbY8qMMWU5OTmnONQBcT4vgC4uUkqpCG71cqkAiiK+LwSq3BhgNAGvplyUUmooV3q5AI8DN9rVLquBFmNMteujtcX5NeWilFJDudXL5S/A1cABoBO4eXSGa9EZulJKDedWLxcD3O7u0EYW59cculJKDTUuV4rqDF0ppYYblwFdc+hKKTVczAFdRLwiskVEnojyXJqI/ElEtonILhE5Izn0YK8GdKWUcpzKDP0LwJ4Rnrsd2G2MWQysBb4vIoHTHNuIspPjAKhrD47WSyil1LgTa3OuQuA9WHuGRmOAFLFKYZKBRiDkygijSAh4yUmJo7yhc7ReQimlxp1Ym3P9CPhHGLEX1j1YtehV9jEfMcaMaj6kKCOB8kYN6Eop5YhlYdF7gePGmM0nOOxKYCswBVgC3CMiqVHO5UovF4DizEQN6EopFSGWlMsa4P0icgT4LXCJiPxqyDE3A4/Y3RYPAIeBuUNP5FYvF7ACenVLF726yYVSSgExBHRjzFeMMYXGmBLgo8DzxphPDDmsHLgUQETygFLgkMtjHaQoM5F+A1XNXaP5MkopNW686zp0EbnNWf4PfAs4T0R2AM8Bd5xgMwxXFGcmAmjaRSmlbKeyYxHGmBeBF+2vI5f+V2E17TpjijSgK6XUIONypShAXmo8Aa9HA7pSStnGbUD3eoSFU1N5amcNIb0xqpRS4zegA9x20UyONnTyyNuVWA0flVJq8nKll4v9/FoR2Wr3cnnJvSGO7PL5ecwrSOUfH97Omu88T3dvH3/ZUU11i1a+KKUmH1d6uYhIOnAv8H5jzALgutMf2smJCA/evIJPrC6mqqWbzUeb+Nyv32b9y6NaMamUUmclt3q5fAxrYVE5hPcePSPyUuO56bzpADy6pRKA3VWtZ+rllVLqrBHrDP1HWL1cRrr7OAfIEJEXRWSziNzoxuBiVZKVSMDn4amdNQDsrm7VnLpSatJxq5eLD1iONYu/EvhnEZkT5Vyu9XIZ9OJeD7NykmkPWg0e27pDVDRpHl0pNbm41culAnjKGNNhrxB9mej7kLrWy2WouflWI8isJKsN+y5NuyilJhm3erk8BlwgIj4RSQRWMfJmGKNijh3Q37d4Ch6x0i5KKTWZnNLS/0hOHxdjzH3GmD0i8hSwHSvPfr8xZqdLY4xJqR3Ql03L4LUD9ezRgK6UmmRc6eVif38XcJdbAztV58/K5l/eN58r5ufx+NYqjmlLAKXUJDOuV4pG8ns93LxmOvF+L1PT47WtrlJq0pkwAT1SQXoCrd2hcNWLUkpNBhMyoE9JTwCgWmfpSqlJxLVeLvYxK0SkT0SudWd4787U9HgAKjWgK6UmEVd6uYAV8IHvAk+f7qBOV0GaNUOvau4e45EopdSZ41YvF4DPAw8DZ6yPy0hyU+LweoTK5s5wtUtHMERPSPumK6UmLld6uYjIVOCDwH3Rnj/TfF4P+anx/PrNci686wX21rTxvv96le88+c5YD00ppUaNW71cfoS1MXTfSc41Kr1copmSHk9zZy/GwP2vHOJQfQdvHm5gX20b//bEbvr7tXmXUmpicauXSxnwW/uYa4F7ReQDQ080mr1chnLy6D6P8PDbFQDsq23jgVcOc/+rhzlY1z6qr6+UUmeaK71cjDHTjTEl9jF/AD5njPnjKIw3ZiunZ7JgSiofXVmEMxnv7TM8ts3qmb6jsmUMR6eUUu5713XoInKb08/lbPSJ1dP4899fwMWluQBcOMf6jaC717oNoAFdKTXRuNbLJeKYm053UG46b2Y2a0tz+IfL57ClvIm27hBpCX52akBXSk0wE3KlaKSEgJcHb17JosJ0FkxJJSXex/sXT2FXVSt9emNUKTWBTPiAHumLV5Ty3b9ZxOKidDp7+jg0wo3RL/9+Gw9tLD/Do1NKqdPzrvuhj0crSjIBwhUubx5uZHZeyqBjjDE8vq2Ktu4Q168sPuNjVEqpd8uVXi4i8nER2W7/eV1Ehm0/dzaZkZ3E1PQEXtxr1cK3B0NUt1h9X5o6ewmG+mnoCI7lEJVS6pSdygzd6eWSGuW5w8BFxpgmEVkHrMfahu6sJCKsLc3h0S2VrH/5IP/1/AF6Qv387KYVpCb4AWho7xnjUSql1KlxpZeLMeZ1Y0yT/e0GoNCd4Y2etaW5dPb08e2/vMPS4gxKspL49M83hcsZ69t1hq6UGl9c6eUyxKeBJ6M9cSaX/p/MeTOzSEvwc3FpDg98soxvf2ghXb19PLmzBoDWbm3mpZQaX9zq5eIcezFWQL8j2vNncun/ySTF+XjxS2t54JMr8Hs9lOZbmaQNhxrCxzR2DKRd/u+tco7Ud5zxcSqlVKzc6uWCiCzCSslcY4xpGPr82SgjKYDHIwAkx/koykwYNCvfV9vG49uqqGsLcsfDO3jw9SNjNFKllDo5V3q5iEgx8AhwgzFm36iM9AwozbNm6QGf9c/yw7/u4+8f2sIjdnOvvTVtAHT19PHQxnKM0YVJSqmzh1u9XL4OZGF1WdwqIptcGd0ZVpqfDMC8fKs2fduxZgD+95VDgDVjB3h6Vw1feWSH9oNRSp1VXOnlYoy5BbjFzYGNBSePvnBqGtsqWsJdGuvtEsaGjh7q24PUtFpb21U2dbGoMH0shqqUUsNMqqX/J+PMzEvzU8JpF7/XyrHPyEkCYF9NG7VOQNdNqJVSZxEN6BFm5Sbzo48s4QNLp5KTHAfANUumAvCRsiIA9ta2cbzVqlHXTaiVUmcTDegRRIQPLJ1KaryfrOQAAH9/yWy+9p553HhuCZlJAfbVDszQnXYBSil1NnCrl4uIyN0icsDu57LM3WGeeVlJAdIS/BRlJnDLBTNICHiZk5fM3po2atusgF6lKRel1FnErV4u64DZ9p9VwE84i3u5xOKGc6dx6bw8RCT8WGleCg+/XUlvn1WrXmmnXIwxGEO4pl0ppcaCK71cgGuAXxjLBiBdRApcGuOYuGRuHp9YPW3QY3PyU2gPhgiG+klL8FPfHiQY6uObf9rNx+7fMEYjVUopi1u9XKYCxyK+r7AfG+Rs6uXybpRG9E5fUpQOQE1LNxsONbDpSBPBUB/GGG7/zdu8uPf4GI1SKTVZudXLJVquYdgyyrOpl8u7MTtKQC9v7ORQXQehfsOB4+3UtQX58/ZqntldO0ajVEpNVm71cqkAiiK+LwSqXBnhWSQtwU9BWjwAS4vTAXj1QD09dk59T3Ubh+0GXscaO094LmMMf91dq/uaKqVc40ovF+Bx4Ea72mU10GKMqXZ/uGOv1F58VFaSSVZSgN+9NZBpeqe6lSMNVkAvP0lA33KsmVt+sYnn39HUjFLKHW71cvkLcAg4APwv8DkXxnZWWjU9i5KsRJLjfFw0J4emzl7AWpS0p6aVw/VWIK9s6qIjGArXrA913H58//G2MzNwpdSE51YvFwPc7ubAzlafuXAGf3vBdADWzs3lkS2VFGYksLw4g2f31JIcZ/2ThvoNX/r9Nt460shbX71sUPkjDPSHOVynPdaVUu7QlaKnyOMRfF7rn+3C2dl4BObkpXBOYRqNHT28frCBlHgrqD+1q4b69p5w8I7kbJ5xWDfNUEq5RAP6aUhPDPDlK+dy47nTeO+iAuJ8Htq6Q1wwOxsAp116eePwoN1g71nqBPTu3j5tJaCUOi0a0E/TZ9fOZG1pLumJAT5gN/I6d0ZWuEsjRL9B2tAx0JK3pbOX7z29l/f912tnZtBKqQkpljr0eBHZKCLbRGSXiHwzyjFpIvKniGNuHp3hnt0+df50MpMCrJieSWFGItnJAUSgvGH4zLshIg1zqL6d5985Tn17kM6e0JkcslJqAonlpmgQuMQY0y4ifuBVEXnSXuLvuB3YbYx5n4jkAHtF5NfGmOHJ4wmsND+Ft//5cgBuPHcafq+H/37hAEcjUi4HjrfR3NlLY0cPM3OSOFjXwWsH6jlkp14a2ntIzDyle9VKKQXEENDtCpZ2+1u//WfoahgDpIhVypEMNAKTeqp58xqrEubxbVWDFhl95ZEdHGvsItTfz9rSXCqaunjg1cPh5xs6eijKTDzhuZ/dXcvTu2r43nWLR2fwSqlxKdbmXF4R2QocB541xrw55JB7gHlYq0N3AF8wxgzr+zLee7m8G9MyEznaYAX0+vYgm442UdPaTX17D/mp8Xxl3dxwLTsM3Cw9kb/uruUPmytGrHFXSk1OMQV0Y0yfMWYJ1pL+lSKycMghVwJbgSnAEuAeERnWZne893J5N4ozEzneFqSrp4/n9tSGK18AspIDfPK8Em67aCY3nVcCDNwsPZHjdj/2t482jcaQlVLj1ClVuRhjmrEWFl015KmbgUfs9rkHgMPAXDcGON7NyEkG4IL/fJ4fPrufrKRA+LnMpAAiwp3r5vKPV5UCg2+WRtpT3cqft1fT3NnD8TZrFv92uQZ0pdSAWKpcckQk3f46AbgMeGfIYeXApfYxeUApViuASe+KBXl877rFXDA7B69H+PQF08lLtfYrzbb3LQVIDPhIDHijplx2VLSw7sevcPtv3ub+Vw5TFw7ozWfkGpRS40Ms5RQFwM9FxIv1AfA7Y8wTTh8XuwXAt4AHRWQHVivdO4wx9aM16PHE7/Vw7fJCrl1eGH7srcON1LbWkRkxWwcrBVPV0sXtv36bi+fmhn9mw6EGANIT/Rysa6e+PYhHYEdlCz2hfgI+XU6glIqtymU7sDTK45G9XKqAK9wd2sQ1ryCVF/bWDUq/AGQlxfHyvnragyH+vKOaxo4gt144k81Hm5iWlci0rCS2lDfTb2BFSQZvHWniUH07c/Oj7QqolJpsdGo3Bq5fWcyd6+aSkxI36PGspADtQavac05eMo9trcIYw+byJpYXZ1CcmUCNXdkyv8AK4k0dvSilFGhAHxNFmYncdtHMYR0Ys5KtGfvU9ATec84Udle3squqlbq2IMumZVAcUZ8+y949qaVLA7pSyqIB/SySZd8kXVKUzqoZmRgDdz+3H4DlQwL6nFyreqala1ItxlVKnYArvVzs49aKyFb7mJfcH+rE5+TUFxWmsaQonYDPwzO7a5mbn8KcvJRBK0hnhQP6wAz9qZ01rPnO83QEJ/UiXaUmrVhm6E4vl8VYi4ausreZC7PLGu8F3m+MWQBc5/I4JwUnp76oMJ14v5elRel4PcL3rluM1yPhgJ4a7yMzKYDPIzRHrDLdcKiByuYuth5rHnTe/n7DjoqWM3YdSqmxEcueosYYc7JeLh/DWlhUbv+MbpT5Llw+P49vXbOAVdMzAfjn985n/Q3LWTg1DYDUeD8ZiX5yU+MREdIS/LR09dLU0UNXTx8H66y3aegK0mf31PK+e17VhUhKTXBu9XKZA2SIyIsisllEbhzhPJOul8upSAz4uOHcEjwe62bpwqlpXDovb9Axs3NTKMpIACAt0U9zVy8f/p83+NcndnPwuBXQN5c3Eerrp7/f+tw9YD/+9M6aM3UpSqkxEFOfVmNMH7DETq08KiILjTE7h5xnOdZq0QTgDRHZYIzZN+Q864H1AGVlZUNn+SoGP75+CR67OiYtwU9jew8H69pp6uylvj2I1yNsOtLEed95ntbuXm69cCa1LVap4zO7a7lz3dxh1TWRKpu7+Paf93DXdYtIDGgbX6XGE7d6uVQATxljOuwVoi8D2tt1FBSkJZCXGg9AeoKf/cfb6DdWJ0eAi0tzaA+G6Os3TM9O5vGtleEdkw7Xd4TTMiN5aW8df95Rzb7aEx+nlDr7uNXL5THgAhHxiUgisArY4/JY1RDpiYFhG1DfvGY6S4vTWX/jctYtzOdoYyf7atvCeflndtcC0BEMhVsKRKposoJ/q9a3KzXuxDJDLwBeEJHtwFtYOfQnROS2iH4ue4CngO3ARuD+ISkZNQrSEvzhr0XA6xFWlGTy6OfWsHxaJnPzUzDGasm7anom50xN41k7oD/4+hE+un4DVc2Dt8c71mR939qtAV2p8caVXi7293cBd7k3NHUykQH9ojk51LYGBzXqmlcw0OOlOCuJy+d7+OFf93G8tZstdsXL5qNNTElPCB83MEPXWnalxhtdKTqOOQE9Jc7H3dcv5RefWjno+cKMBJLjrM/s4sxErliQhzHw1z3Hw7XqTinjtmPN7KpqoeIkM/SWrt5w9YxS6uyiZQzjWHqiFdAL0uNJjfdD/ODnRYS5+SlsOtpEcWYiealxlGQl8r+vHArn3t8+2kR3bx+f/vlbpMT7w73Wo+XQ+/sNF3/vRT6yoog7rtL9S5Q62+gMfRxzZugFaQkjHnNOYRrJcT5yU+IQET6xehqH6zsAuGB2NruqWvnNm+XUt/eEH4foM/SWrl4aO3r4+etHaIphqzyl1JnlWi8X+9gVItInIte6O0wVjTNDj8yBD/WFS2fzu8+cG16s9JEVRSTH+Qj4PHxsZTGhfsN3nnwnvIuSw8mht3T1UmPXsTulkZ09fTz4+hG3L0cpdZpc6eUC1mpS4LvA066OUI3ImaFPSYsf8Zj0xADzpwzcHE2J9/MPl8/h46uKuXhuLp9dO5PL5udy90eXhoN6fmo8rd1Wrvymn23kpp9tBKDODuh5qXE8+PqRcO92pdTZwa1eLgCfBx7Gag+gzoAp6QnMyk1mpV1jHqtPnT+df3nfAuL9Xu64ai73fnw5q2ZkcXFpLokBLzNzk2jt6uWxbZVsKW/mwPF2Qn394bz7l6+cS0tXL7958+iwc9e0dPOrDUcxRm+cKnWmudLLRUSmAh8E7ovy45HHaS8XFyUGfPz1Hy5i1YwsV853x1Vz+b9bzyU9IUBLVy/3PH8Ar0cI9Rsqm7uot2+YXjo3lzWzsrjvpUMcs1ehOv7tz7v52h93hlenxsIYw9U/foXfbix35TqUmqxiCujGmD5jzBKgEFgpIguHHPIjrI2h+05ynvXGmDJjTFlOTs67Ga8aRRlJAc4pTCM1wUdDh3WTdGWJNfs/0tBJfXsQn8fq8viN9y2gr99w4083hm+gHqnv4C87qgHYXdUa8+u2dofYXd3KL94YPuNXSsXOrV4uZcBvReQIcC1wr4h84PSHp8ZCaryf5s5e+g1cVGp98B6p76C+PUhWcgCPR5idl8L9nyzjSEMH/2XvqvQ/Lx/E5/Xg9Qi7TiGgOzdbd1e3cugkvWaUUiNzpZeLMWa6MabEGFMC/AH4nDHmj66PVp0RqRErUFeUZJAY8HKkoYP69h6yk+Minsvkw8uL+NlrR3hlfx0Pb67kuuWFzM5NZnf1QEDv6zd09478y5tT+w7wp23VLl+NUpOHK71c1MSSGj+w3mxaVhLTspI4aqdcIgM6wJeuLCU1wc+NP91IqL+fz1w4k/kFqeysbOGHz+5jZ2UL9710kEu//9KIN0qdGfrU9AT+5+WDbDzcGNM424OhQbXzSk12sVS5bDfGLDXGLDLGLDTG/Kv9+H1D+7nYj99kjPnDaAxWnRnODD0p4CUrKUBJVqKVcmkbHtBzUuJ46G9Xk5Mcx4fLiijOSmT+lFSOtwX58XP7+elrh3lpXx2VzV3UtgajvVx4hv7ATWUUpMXz2V9tjqlK5u7n9nPNPa9qRY1SNl0pqoZxAvq0rCREhJLsJMobO6lp7SY7JTDs+NL8FF694xL+/YPnAHCOvWWe3yu8eagxvJ+ps3PSUM7GHHNyU7jpvBIaOno43hY9+EfaUt5Ea3eIRl21qhSgAV1FkRrvBHRrU+qVJZmE+g39BrKT4qL+TMBn3QwFWDk9kwc+WcY/XF5KZXMXXXb+fKTNNerbeshKsm62Ts9OPuGxjv5+E66kqbZXsio12WlAV8OkJVg59GlZSQCsLc0hN8UK5MnxJ+/nJiJcOi+PNbMG6uO9HmHz0SbW3vUCz79TO+j4uojc/Iwc6zWd3PgDrx7m1f31w17jaGMnHT3WB8XQnu5KTVau9HIRkY+LyHb7z+siotvPjWM5KfHE+z0sKrRSJyLCTz6xnJQ4H8uKM2I+z/yCVJICXrKTAyycmsYT26s40tDJT148CMDmo418/qEtVLd0k5My0HYg3u/hUF0H+2rb+NYTu/nlhiPDzr2rqiX8tc7QlbLE0j7X6eXSLiJ+4FURedIYsyHimMPARcaYJhFZh7UR9KpRGK86A9IS/Lz5lctITRj4z2P5tAx2fPPKUzqPz+vh/UumEOfz0tYdYpvdg/2tI03sqW7lq4/u5J2aNgDmFxQC4PEIJVlJHK7v4D478Fc1Dw/YOytb8XutFE9Vi87QlYLYdiwywAl7uRhjXo/4dgPWilI1jqUl+k9+UAz+40OLALj3xQMA3LB6Gv+36Rif/OnGQTc+nRk6wMycZF4/WE9rdwivR6KmVLYda2Z2bgptwV6qowT8SK/sr8PrEc6bme3GJSl11nKll8sQnwaeHOE82stlklpRkkm838NNa0q4+6NLyUmJY82sLC6YbQXZ7OSB6pnp2Uk0dfaS6Pdyw+ppNHT08MT2KtZ853l2VLRQ3tDJhsMNXDYvl4K0BKpPMkP/tyf28J9P7T3ta9hX28Y/PbqDPt2xSZ2lYtqxyO7RssReMfqoiCyMtgm0iFyMFdDPH+E867HSMZSVlen/FZPIipJMdn3zKrweYWZOMlctzAfgwdcO88r++sEz9Fzrxuj/u3xOuOf7/711jMrmLj5+/waWFGfgEeFjq6ZR3tjJW0eaRnzdvn7D4YaOQfuvHmvsZEp6Al6P0BEM8XZ5ExfMPnlvob/uqeU3b5Zz24UzKbYrgJQ6m7jVywURWQTcD1xjjGlwY3BqYnHKGiNdvaiAVdMzB91svWpBAT/48GJuPHdaeDemDYcamJWbTGFGIi/vq+OK+Xnkp8VTkJ5AbWs3ff2GY42dNHcOrkmvbOqiJ9RPXVuQ7t4+jrd2c8n3X+ThtysA+Omrh7nhgY0x1bK3dFpNyCojUkDGGN1jVZ01XOnlIiLFwCPADcaYfaMwTjVB5abE83+fOZeizIEZb0LAy4eWFeLzephq78bU22dYPSOTx/9uDXdfv5RvvH8BYG3uEeo31LcH+dj9G/jOk4P+0xxUz17d0s22ihZ6+wyb7Vn9m3abAaf9wIk02wE9Mqf/wKuHWfu9F3W1qjorxJJyKQB+bu9I5AF+5/RyAasFAPB1IAuryyJAyBhTNkpjVpNIXlocImAMzM1PtSpnFk8JP+98EGw71syxxi4OpQ3u7RIZ0CubusLljruqWwj19fN2uRXYY5qhdw0P6G8daaS8sZP69p5BaSOlxoIrvVyMMbcYYzKMMUvsPxrMlSvifF5y7EVH8wpShz0/337ssW1VAMNukB6s68DJ9FQ2d4bb+u6taWNbRTOd9uKkaJte9/b187U/7gh/KDR3WcdElkkerLM+QIY2CTvW2Mndz+3Xmbs6o3SlqDrrOZtgl+anDHsuJyWO7OQAf91trT6taekeVIVysK6dcwrTEbFm6LurWkkKeOntM/z6zYEdkho7e/je03vZfHTgBuvOyhZ+taGcP2y28u3N4Ry6VSYZ6uvnaIMVyI/YAf33m46x+Wgjf9pexQ+e3Tco3z4antpZw7O7a09+oJoUNKCrs96s3GTm5CWTHDc8QygizJ+SRjDUD1i59se2VnL5D17i7uf28051K6V5yeSlxLOrqpXK5i7eu8hK2Ty2tYpiO2VzrLGLe144wL0vHAif21kI9bYd5IemXI41ddHbZ314HG7o4GBdO3c8vJ37Xzkc7iAZS5Ox0/GfT7/D+pcPjuprqPFDA7o66339ffP51adHXng8f0gq5mevHWH/8XZ+8Ow+vB5h3cICpmYk8OoBqyfMexYVkBTw4vMIP/roEpLjfOHc+iv762kPhgDYbneJ3F5h5dudGXp1cxfGGA7a3SM9Ys3Q//uFA/QbK4iHA3rr6LUl6O7t40h9Bx3BE+78qCaRk94UFZF44GUgzj7+D8aYfxlyjAA/Bq4GOoGbjDFvuz9cNRmlxvvDHSCjmT/FCugLp6ays7KVHZUtrJyeyQ8+vJj81Hh8Xg+Pbqlk89EmZucms3J6Jt94/wKmpCewrDiDzKRAuHNjT18///7n3RSkJbD1WDPxfg9dvX1sq2ihq7ePzKQAjR09tHaFwrn1ZcUZbDraRGNHDyJQ29qNz07cj9QD3g0HjrfTb6CjJzRqr6HGl1hm6E4vl8XAEuAqEVk95Jh1wGz7z63AT9wcpFInstAO6BeX5oYfO2dqGoUZifi81n/iiwrTyE2J46c3rSDe7+W6siLWzLJWqWYkBWiwb4rG+Tw8tPEYP3h2H4fqO/jgUquLxQvvHAcGfhuobO7iYF072clxLCpMp67N2kD7g0umcrx1YIZee4oz9KMNHXT1xDbj3mv3wdEZunLEUuVijDEn7OUCXAP8wj52A5AuIgXuDlWp6GbkJPOTjy/j1gtnkBTwAgObbDhuuWAGr995yaB6d0emvRpVBH780SX8598s4qI51srRdQvzyU2J48V9VkBfMNUK6IfrO9hb287MnCSmZ1vnvH5lMQunptHT18/Rxk5gYIb++LYq/mRX4oykv9/w3rtf5e7n98d03XtrrYDeqTN0ZXOrl8tU4FjE9xX2Y0PPo71c1KhYd04BKfF+CuyKmIVTh5c4OrP1oTKSrD4yOclxXLWwgA+vKOIHH17Ml68s5dyZWcyfkhoud1w9I4sEv5cX9h5nZ2ULZSUZnD87h3NnZPHZtTPJS40HCFfaODP0/37+AP/6xO4Tript7uqlLRji9QPD+79H43Sq7Ozpo7/f0NkTYvW3n+OFvcdj+nk18cQU0I0xfcaYJVhdFFeKyMIhhwxf0z18Fo8xZr0xpswYU5aTc/LeGUqdqinpCSQGvOGdj2KRZQd058MAICs5jtsvnoXf62FufipOOXlOchxlJRn8cUslff2Gc2dkMz07iYduXU1eajx5qYMXF9W2dmOMobyxk7q2IDsqWxjKGEN7MBRO0+ysaqUjePJZ996a1vDXnb19VDV3UdPazZajI/e2idWhunbdgHsccquXSwVQFPF9IXDi3y+VGgXXryji7y+dHbVvzEicGfqUtPioz88rGKh/T0/0s2q6tSWf3yssnzZ4ww9nhg5QnJlIbWs3DR094W34ntszvGb88W1VrP72cxyxa9r7+g1byptPOObu3j5qW4Pk26/XGQzR0G7dB6g8STvhWNz58A7++Y/D+u+ps5wrvVyAx4EbxbIaaDHGVLs9WKVOZt05Bdx20cxT+pnMRHuGnpYQ9fm5+QPpm/TEAKtnWFvrLSlKJ8HO2Tsil/8vnJpKa3eIfXauO+D18Oye4emQvTVttNtdHx0bjzQOO27j4UYe21oJDPSemZ5tdabs6OkLty9wY0u+Y02d4ZWxbvrTtir+skNDw2iJZYZeALwgItuBt7By6E+IyG1OPxfgL8Ah4ADwv8DnRmW0So2C8Aw9PfoMfUZOEn6v4PMISQEviwrTyU6O49J5ecOOjfd7wy1/F0yxbsw6jcCuKytkT3UrGw4Nbkbq3DjdfsxKx0xNT2BL+fC0yQ+f3cd//MWaSzkLlkqcgB4MhSt1ovWH/8ojO6LuzRpNX7/heFuQzlGonln/8iHuf+WQ6+cFq1VDa3fvqJx7vHCrl4sxxtxujJlpjDnHGLNptAeulFucDaqnpkefofu9HmbmJJOe6EdECPg8vPKPF3PrBTOiHp+XEo/IQH38W3ZO+0tXlJKbEscPnt03qMfL8TYrRbKzsgW/V1hclEZlUxf7a9u4+sevcLytm/5+w87KFho7ejDGcNz+ECix+7J3BEMDM/SW7kE3Xzt7Qjy0sZxHtlTE9O/R0B6kr9+MSn17fXtw1MosH3ztCJf/4KVJ3T9HV4qqSW9pUTr/8aFzuGRe7ojHnDczm1m5AzdaEwJePCPk6XNT48hMDDC/IBUReP1APdnJcWQkBfjs2plsPNzIVrutAAxUwrQFQ2QlxTElLYGqli42HG5kd3Urz+85zqH6DtqCIXr6+mntDlHXPniG3hmRcukJ9Ydn6wD1bdbXTurnZJxNt92eoRtjaGjvCa/EdVtFUye1rcFww7XJSAO6mvQ8HuH6lcXE+bwjHvO198zjN7cMXU8X3cWluVyxII+81HjOm5lFqN9QnGnN/q9dXkicz8Mft1SGj49cTZqdEiA/LZ7u3n522q0HXj1QH+4rA9YMuq61GxHCvWg6ekKDgnhkHr2u3QrQ+2vbY9o+r8b+gOnoCQ2a7bZ29xIMvftg6XwgjdbKVieQx9IKeaLSgK5UDDweGXFGPtSnzp8e3hzbWWnqLGhKifdz2fw8/rS9mt6+frp7+8JNv8BK/zjdJd+yb4y+cbCBbRXN4WPq23s43hYkKymOVHtrPSvlEgwvrPrS77fxyZ9uBAiXQwZDA90hT6TGnqH3G8JNz4wxfOCe1/j3P++J6d8gmnp7HB3B0EnTIv/8x528FmM9vqOzVwN6LFUuRSLygojsEZFdIvKFKMekicifRGSbfczNozNcpcaXqxbmk57oH9RA7INLptLY0cPDmyvCuXC/1/qwyE6Oo8AunzxUb/Vyb+jo4fFtVWTYN1sb2q3WArkpceEA3hHso6G9J3wjdv/xdl7aV0djR084oENsaZeaiHYFTj38tooWDtV38E51bGmbaJzfIHr7TPiDIpru3j5+ueEoz+yqOaXzd+kMPaYZegj4ojFmHrAauF1E5g855nZgt93vZS3wfREJoNQklxzn46UvX8ynz58efuyi0hzKpmVw5yM7+MlLVrve+XYgzkkZmKGDlb4J+DwI8MUrSgGo77Bm6DkpcSQGrP56nT3WTdEZOUkkRpRSvnmogbq2ICJWawNndWk0rd293PbLzWyKKJl00hhP2qWGx5o6R/z5vTVtXL9+w6DfOCLVR3ywnGjhlPMB1HCKgdk556n+3EQSS5VLtdM50RjTBuxh+LJ+A6TYXReTgUasDwKlJr20BP+gtgN+r4df3bKKRYVpPLTR6pixtCgdsGbo2clx4W6Ny0syePUfL+bNf7qMj66w1u7VtwU53tZNbkocAZ+HgNdDm13lkpkUYN3CAr54+RwS/F42HGqgrt1Kz0zLTDzhDHv7sRae2lXDW0cGSiadPPqTO63Zck1rNz0jzK6v/cnrvHGoIdyKeKj6iEB7okoXpyTzVGfazuKtaLtPTRanlEMXkRJgKTC0l8s9wDys1aE7gC8YY4a969rLRSlLvN/LdcsLw98vLU4HIDs5gNcj4RWnhRmJ5KbGE/B58Hk9ZCT6qWsPUt/eQ67dZiAxzktNSzehfkNmUoDvf3gxn790NmUlGbxhz9BzUuI4d2YWL+47PmLAi0y1pNibiXQE+zhU30F5YydLi9MxJnqd+6G6dtrsGXJbd/S5XEPERtxtwZHrxevsMs6hAf3pXTUjzv5h4LcJnaHHQESSgYeB/88Y0zrk6SuBrcAUrBa794jIsO5I2stFqQFXLsxHxFpBurY0lyvm57FqurUK1VnkVJQxuDY+OzmOA3a1irPXalLAxzG7u2NW8kCm89yZWeyrbWdPdRs5KXHcdN50unv7+c3GcqKpiQjUM+wSzc6eUHhbvg8tsz6AjjUOD+i/idjOr7kzekCtb49MuYw8Q6+LMkPfXdXKZ365ObxSNpquE+wPO1nE2m3RjxXMf22MeSTKITcDj9gLjA4Ah4G57g1TqYknNyWeVdMzKUiPJy3Bz/oby8i3b4jm220ICjMGt/vNSg6wp9qaT+Xas/jEgJdjTVaQzUwaaD1w4Wxr0lTZ3EVOchyl+SlcMDubX7xxZFD5Ysiutqlu6SYj0c+PP7qEz9rtEzqCfbx9tIm0BD9r7ZbCFVHy6K/sr2eZ/VtGY0f0WbTTa8Y678gZWSfl0tTZE66GcXrgNI1wbhjY6ENn6Cdg58UfAPYYY34wwmHlwKX28XlAKVYrAKXUCdx17WLuuX7ZsMfn5qeQa2+AHSkrOY62YAiPQFmJ1RgsKc4XntU6nSPB2ozD+Xmnx8x1ZUXUtgYHtRb4tz/v4SPrN1Db2k1+WgLXLJkabkjmzNCXFadTkBaPzyPhG6NVzV28cbCBY42d7K1t47L5eQR8nqgz9M6eEPXtwfCq3LYYbor29hla7fTNc/YGIyda2u+kXJpG+A1hMjjpFnTAGuAGYIfdEx3gn4BisFoAAN8CHhSRHVitdO8wxpxaEalSk1BRZiJFmcMfv/XCGXxi1TSs+dQAJ81ywewcclOsGXpSnFXVEufzMDtvYDWrxyNcODuHR7ZUkmsH9LWlOfi9wtO7aigrsV5467Fmtlc0Mz07iWl2vbxTPVPd0s3+4+1cs2QKPq+HgvR4Kpq6OFzfwSXffxFjCJdTXjArh1+8fnRY7vuV/XV86sG36O0zLJ+WYS//P/kMHay0S0+oP1yHP1IOva/fhG/WulG22NTRE+7xM57EUuXyqjFG7F4uS+w/fxnSy6XKGHOF3cdloTHmV6M/dKUmLr/XQ1ri8H1UnRn4h5YNFJo5wXdZccaw1a4XlVppkmw7oKfG+zlvZjbP7K4NpzOONnRgDByq6winepwPidcP1ofPDVCUkcixxk6O1Fs/86FlU2nq7LVq7aekkp7op6lzIOh29/bx1Ud3hlM8yeGbrQMB/Y2DDeH9WcGaoTt1+Y0dQd483IAx1r2G1hECeuSuTZE3X9+NY42dLP+3Z2PeaORsoitFlRpHzpuVzUVzcrhifn74MacR16oZw6f6V8zP55bzp3Ph7OyBxxbkcbShk3217bR09g4KwE5/9Xif16pbt8scZ9o3SaemJ1DZ3BVuKPb/LpvDp9ZM5+bzpuP1CJlJgUEpl4ffrqC8sZMHPrmCj5QVceuFVkMzpxKmu7ePW37+Ft9/Zm/4Z463dTMzx3q9hvYe9tW04RGYNyV1xJSLk27JTYmjtTtEb9/IC5dOprqlm37DsK6Y44EGdKXGkeXTMvj5p1YO6sO+275J6lTIREoIePnae+eTnjiQPrh8Xh4i8MyumvCmGg5nlarHIyT6vTR09OD3SjjVU5AWT11bMNzAKycljq+/bz5fuGw2ABmJARojAvqOihYyEv2sLc3hu9cuYs2sbBID3vAM/ZX99XT09HGk3srL9/cb6tt7mGevrG3s6GFfbTslWUnkJMfR0hU9VeME9EK7Kuh08ujObD/a7lJnOw3oSo1zC+w2vU4t+8nkpsaztCidZ3bXhgN6pp3KyY/YtSnRTo/kp8WH+9jkpyXQb2BXVSup8T7i/YNTPOmJfpojZvx7qluZV5A66F5AcpwvXJHirEAtb+zEGENjZw99/YY5edZN2cbOHvYfb2NWbjKpCb6TplycqqDTyaM75Y87KlvHXSteV3q52MetFZGt9jEvuT9UpVQ0P/zIEp774kXDguuJXLEgnx2VLbx+oAERuMxuHRwZ0J0+MZE7OTkz+O0VzeGyyUhOyqW/39DXb9hb2xaebTuS43y0dYfo7u3j2T21BHwe2u2VrhV2+WVxZiIJfi+1Ld0caehkTl4KqfH+EVMuThB2UjUn2rXpwPE2fvbaYZ7aGX3nJGe2X98eHHSDdjxwpZeLvUXdvcD7jTELgOvcHqhSKrqUeH84kMXqivnWbkuPbqmkIDWeK+bnMzU9gaKIuvcke4YeufGHE/BrW4PhyplI6YkB+o1VXnikoYPu3n7m5qcMOiYpzkdHMMT6lw/R1h3i5jUlABxt7OSPWyrxe4VVMzLJTAqw6WgTff2G2XnJpCX4aesORW0B7ATh0nzr3yHa4ifHl/+wnW/+aTd/95sthOxc+8G69nC5ZOQN1h0V4yvt4lYvl49hLSwqt48bvnGiUuqsMSMnmRtWT6Onr59pWUlcNj+P1+68ZFBuPsmunimImLVHfp0TJaA7JYxNnb3hBVDRZugH6tq598UDvOecgnALhL01bTz8dgXrFhaQnRxHVnKAXVXWOWbnpoRbBbdHaS0QmXJJ8Hspb4zeRKyv3/BOdRuJAS+hfhPeKOTWX2ziu0+9Y59rYBXr9oi2xY4Nh6yqnOffqWXlv/910AfAWHOrl8scIENEXhSRzSJy4wg/r71clDpLfPU98zh3Rla4tHGoRLt0MbL7Y1qCn3i/FTaizdCd2u3Gjh72VLfi9cig2niwZujHGrsIhvq5c91cCjMSEYH/eekgbd0hPr6qGIAbVk8L7+U6IyeJ1HjrAyYy7fLmoQa6e/vCQTg5zkdhRkK4FQLApiONfOR/3iAY6qO8sZOu3r7wKlqn93tdWzC8c5RzrnOmpvHqgXoO13eENyQ5XN/BjQ9s5AfP7GNLeTPH24KD2hOPtVgWFgEn7eXiA5ZjrRZNAN4QkQ3GmH2RBxlj1gPrAcrKysbX3QalJph4v5eHbh15FyZnhh6ZchERCtISOFzfMcIM3QrozZ09bK9oYXZu8rDa+GT7g2LV9Mzwxh/5qfEcaejknKlprJxulV9eV1bE0uJ0alqCxPu94Rn6scZOvB6huqWbj6zfwKzcZC6Za90DSAx4Kc5MHDRDf2lfHW8ebqSquZt37N8a1pbm8NSuGmrs/VfbgqFwa4Ku3j7i/R7Wlubw3y8c4Eu/38bb5U1cPj+Prz+2k56+fiqaOsO/zbSOUHkzFtzq5VIBPGWM6bBXiL4MLHZvmEqpM83pq16QPvjmp1Or7qxUjZRpB/S6tiBvH21iRcnw2vjD9VZlzQeWDGRuncD+d5fMGlQRMys3hfPtGvo0O6B/8ffbuO6+N9h81OrbXt7YyQOvHgasMs2izEQqmrrCK1Kd4N7QHmSPXdN+gd2Xpqa1m/aeEMYMlDp2BEMkBnxcOCeHfgObjzZhDPx1Ty2v7K8n3u+hsrk73HWyLeI3hg2HGvjWE7tH/Dctb+iku3f09jx1q5fLY8AFIuITkURgFVauXSk1Tjk3RSNTLjCQR482Q89LiyMl3seDrx+ho6ePFdOHB/TiLGtj63ULC8KPnT8rm3NnZHH5vLwRx5MabwX06pZuKpu7eHRLFYUZCSyckhq+UZoY8FGUmUh7MMQVP3yZb/5pVzj9Ut8e5J3qVkqyk5iSFk/A66GmtTtcCtnYYTUD6+rpIzHgZUlRenhlK8Bv7d71l8zNpb49GK6dj0wB/WFzBQ+8ejjqwqZ3alq58K4XWPzNZ/jvFw6MeJ2nI5YZutPL5RK7LHGriFwtIreJyG0Axpg9wFPAdmAjcL8xZueojFgpdUbMn5LK4sK0cCB1OJUu0XLocT4v711UEN4ZaWWUGfp/fOgcnvviRYNaG/z9pbN56NbVJ9y3NTVhcIZ4T3Uri4vSKbWraAI+D16PhFsON3b0sKW8mXK74qW+vYd3atqYl2/VxeemxlHT0h1OmQRD/XTZ+fjEgBe/18Mnz5vG314wncSAlzcONRDv93DRnIEuljA45XLgeLv92PDyyrcOW79RfGjZVGblnlpVUqxOmkM3xryK1XDrZMfdBdzlxqCUUmPvw2VFfLisaNjjC6akkRLvo2DIzN3xN8sKeWjjMYozEwfVtTuS43wkn2KZJQykXMDaTs8YWFKYjtf+EHDq5ouzBkovD9a141Q5Vrd0caypkw8utVI9BWnxVkCPmGE3tPfQ2dtHgn3/4MtXWl3A3zrSxNZjzZwzNS2cHnI4P2+M4aAd0Js6e8lKHvyBt/VYC9nJcXz7g+cMa7rmFl0pqpQ6JVefk8+mr102KB0Rafm0DObmp4RvVLolKeDDmcA7dfSRM3SnSdn07CRWTs/khtXTiCxZ317RgjHWoiWAvNR4aiNSLmDl0TuDIRKHLNJyaukXF6YPukkMhFv81rUFw22BW7qGr1TdVtHMkqK0UQvmcApVLkopBValy9DKlaHPP/5354f3RXWLxyOkxPvJSPRz85rpNHb0sKgwLTxDdqpO4nxefveZczna0MEvNxy1xwTbjjUDA/1e8lPjeXZ37aCWvI0dPXT29DElfXCayfnQWFyUPuy3jrbuXj73682D+uVEtj8AaxZ/sK6daxZPOd1/hhPSgK6Ucl3ANzq//E9JT2DBlFRWz8ji97edB1h94DMS/eGqHEdRRiJJAS8dPX3Mzk1mX62VDgmXSqbFEwz1h3d7AmuG3hWRcnFcXJrLkztrWDMrmzifl5yUOOraggS8Hmpbu/nLjppBxzcNCeg77N8OFtubgY8W13q52MeuEJE+EbnW3WEqpRT84lMr+cb7Fwx6TERYPi1jWCrE4xHmFaSSFPCGb0L6vQMbcDsz7X32DVywc+g9w1MuJdlJ/O4z54abmE1JT8AjMC0rkf21A73cnT7uQ3dteu1APV6PjHpAj2WG7vRyeVtEUoDNIvKsMWZQsaWIeIHvAk+PwjiVUipqqSTA3dcvRaLUblxXVsi+2vZwGeGU9ITwTVSnM+Pu6laS43x09fZZOfSevkEtEKIpykigvi1IRlIgvJ2f1yOcMzWNrceaB6VxjDH8ZUc1583MGnRjdzS41csF4PNYi4+0j4tS6oxKDPiiBuGPrCjmn987nyx782wnfw4DN0fLGztJS/BbvdztHLqzY9NIvnxlKXdfv5TUeB+9fdad1/s+sZzvXbeY9MQAzZ29PLy5gsaOHnZXt3KkoZOrzyk44TndcEo59JF6uYjIVOCDwCXAihP8/K3ArQDFxcWnOFSllHp3slOsVElh+kDJYUain+Q4H+3BECnxPpKMobY1SF+/CVfMjGRaVhLTspIG1eivnpFJSryf9AQ/2ytb+OWGo3xl3Vxau3vxeoQrF+Sf4IzuiPnOxUl6ufwIa2PoE65pNcasN8aUGWPKcnKiNwRSSim3OTP0oszBfWmcWXpqvDVDr2iyVn8mxNhbPsVuGJYU8JJiB/e0RD+77N2OjjV1sqOylXkFKeH8+2iKaYYeQy+XMuC3dn1lNnC1iISMMX90a6BKKfVu5Tgz9IzBi4KKMxPZXd1KaoKPgM8T3nZuaMXMSJyGYXkRpYzpCX5CdgF8RVMX5Q0dLJiadtrXEAtXerkYY6YbY0qMMSXAH4DPaTBXSp0tFhemc8dVc7l8/uBeMc6q0tR4P9OyksKtcxNHWDQ1lJNyyYtoVJYRUY9+tKGTiqau8G8Coy2WUTu9XHaIyFb7sX8CigGMMfeNztCUUsodPq+Hz66dOexxpyY9NcHP/IiNOIaWLY7ESblELjaK7FHjdJacdrYE9Fh7uUQcf9PpDEgppc6UgRy6b9DOSqeacslNHSinTE+wZug+j4RTL5H9ZUaT9nJRSk1axREz9OnZSeHdmE5Wh+5wUi75ERtmp9sz9OXTMsKPTbNbBo82DehKqUlrWmYi/++yOVy1MB+vR5ibb83Sk2LMoWclW7PxyFWqTkBfW2o1Jwt4PYMC/mjSgK6UmrQ8HuELl80OV784aZdYyxbn5qfwi0+t5NKIjTnKSjJZW5rDB5ZajbgKMwdWp442V3q5iMjHRWS7/ed1EdHt55RS4865M7NIjvPFXDMuIlw4J2dQwJ6ansCDN6+kIC2BzKTAGbshCu71cjkMXGSMaRKRdVgbQa8ahfEqpdSoed+iAi6flxdzDv1k7rxq7qB2A6MtliqXaqDa/rpNRJxeLrsjjnk94kc2AIUuj1MppUadiLgWzAE+vGL4jk+j6ZRy6CP1chni08CTI/z8rSKySUQ21dXVncpLK6WUOgm3erk4x1yMFdDviPa89nJRSqnR41YvF0RkEXA/sM4Y0+DeEJVSSsXClV4uIlIMPALcYIzZ5+4QlVJKxcKtXi5fB7KAe+2OiyFjTJnro1VKKTUiV3q5GGNuAW5xa1BKKaVOna4UVUqpCUIDulJKTRBijBmbFxapA46+yx/PBupdHM54MRmvW695ctBrjt00Y0zUuu8xC+inQ0Q2TcabrpPxuvWaJwe9ZndoykUppSYIDehKKTVBjNeAvn6sBzBGJuN16zVPDnrNLhiXOXSllFLDjdcZulJKqSE0oCul1AQx7gK6iFwlIntF5ICI3DnW4xktInJERHaIyFYR2WQ/likiz4rIfvvvjJOd52wmIj8VkeMisjPisRGvUUS+Yr/ve0XkyrEZ9ekZ4Zq/ISKV9nu9VUSujnhuIlxz1G0sJ/J7fYJrHt332hgzbv4AXuAgMAMIANuA+WM9rlG61iNA9pDH/hO40/76TuC7Yz3O07zGC4FlwM6TXSMw336/44Dp9n8H3rG+Bpeu+RvAl6IcO1GuuQBYZn+dAuyzr23CvtcnuOZRfa/H2wx9JXDAGHPIGNMD/Ba4ZozHdCZdA/zc/vrnwAfGbiinzxjzMtA45OGRrvEa4LfGmKAx5jBwAOu/h3FlhGseyUS55mpjzNv2122As43lhH2vT3DNI3HlmsdbQJ8KHIv4voIT/yONZwZ4RkQ2i8it9mN5xtrjFfvv3DEb3egZ6Ron+nv/dyKy3U7JOKmHCXfNQ7axnBTvdZStO0ftvR5vAT1aG9+JWne5xhizDFgH3C4iF471gMbYRH7vfwLMBJZgbcj+ffvxCXXNsWxj6Rwa5bFxed1RrnlU3+vxFtArgMhttAuBqjEay6gyxlTZfx8HHsX69atWRAoA7L+Pj90IR81I1zhh33tjTK0xps8Y0w/8LwO/ak+Yax5hG8sJ/V5Hu+bRfq/HW0B/C5gtItNFJAB8FHh8jMfkOhFJEpEU52vgCmAn1rV+0j7sk8BjYzPCUTXSNT4OfFRE4kRkOjAb2DgG43OdE9RsH8R6r2GCXPMJtrGcsO/1SNc86u/1WN8Nfhd3j6/GumN8EPjqWI9nlK5xBtYd723ALuc6sbb5ew7Yb/+dOdZjPc3rfAjr185erBnKp090jcBX7fd9L9Zm5GN+DS5d8y+BHcB2+3/sggl2zedjpQ+2A1vtP1dP5Pf6BNc8qu+1Lv1XSqkJYrylXJRSSo1AA7pSSk0QGtCVUmqC0ICulFIThAZ0pZSaIDSgK6XUBKEBXSmlJoj/H6VheHatpUS4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**保存模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), './model_storage/nmt_encoder_gru.pkl')\n",
    "torch.save(decoder.state_dict(), './model_storage/nmt_encoder_gru.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variable_from_sentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = torch.LongTensor([[SOS_token]]) # SOS\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    decoder_hidden = encoder_hidden.view(encoder.n_layers, encoder_hidden.shape[1], -1)\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni.item()])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = torch.LongTensor([[ni]])\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机选取一个句子进行验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 委员会由四个成员组成。\n",
      "= the committee consists of four members .\n",
      "< the is will be to . . . . <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'life is beautiful . <EOS>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(evaluate('人生是有趣的。'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机的验证只是一个简单的例子，为了能系统性的完成测试数据的翻译，这里仍需要实现一个新的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "pairs_dict = collections.defaultdict(lambda : [])\n",
    "\n",
    "for pair in pairs:\n",
    "    pairs_dict[pair[0]].append(pair[1].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bleu_score(size=100):\n",
    "    candicates = []\n",
    "    references = []\n",
    "\n",
    "    for i, pair in enumerate(pairs_dict.items(), start=1):\n",
    "        candicate = evaluate(pair[0])\n",
    "        if candicate[-1] == '<EOS>':\n",
    "            candicate.pop(-1)\n",
    "        candicates.append(candicate)\n",
    "        references.append(pair[1])\n",
    "        \n",
    "        if size > 0 and size == i:\n",
    "            break\n",
    "    \n",
    "    score = bleu_score(candicates, references)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27672111988067627"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bleu_score(100)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.767px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 514.7443639999999,
   "position": {
    "height": "40px",
    "left": "1211.8px",
    "right": "20px",
    "top": "120px",
    "width": "360px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
