{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq模型——机器翻译\n",
    "\n",
    "### 案例简介\n",
    "\n",
    "seq2seq是神经机器翻译的主流框架，如今的商用机器翻译系统大多都基于其构建，在本案例中，我们将使用由NIST提供的中英文本数据训练一个简单的中英翻译系统，在实践中学习seq2seq的具体细节，以及了解机器翻译的基本技术。\n",
    "\n",
    "### seq2seq模型\n",
    "\n",
    "从根本上讲，机器翻译需要将输入序列（源语言中的单词）映射到输出序列（目标语言中的单词）。正如我们在课堂上讨论的那样，递归神经网络（RNN）可有效处理此类顺序数据。机器翻译中的一个重要难题是输入和输出序列之间没有一对一的对应关系。即，序列通常具有不同的长度，并且单词对应可以是不平凡的（例如，彼此直接翻译的单词可能不会以相同的顺序出现）。\n",
    "\n",
    "为了解决这个问题，我们将使用一种更灵活的架构，称为seq2seq模型。该模型由编码器和解码器两部分组成，它们都是RNN。编码器将源语言中的单词序列作为输入，并输出RNN层的最终隐藏状态。解码器与之类似，除了它还具有一个附加的全连接层（带有softmax激活），用于定义翻译中下一个单词的概率分布。以此方式，解码器本质上用作目标语言的神经语言模型。关键区别在于，解码器将编码器的输出用作其初始隐藏状态，而不是零向量。\n",
    "\n",
    "### 数据和代码\n",
    "\n",
    "本案例使用了一个小规模的中英平行语料数据，并提供了一个简单的seq2seq模型实现，包括数据的预处理、模型的训练、以及简单的评测。\n",
    "\n",
    "### 评分要求\n",
    "\n",
    "分数由两部分组成，各占50%。第一部分得分为对于简单seq2seq模型的改进，并撰写实验报告，改进方式多样，下一小节会给出一些可能的改进方向。第二分部得分为测试数据的评测结果，我们将给出一个中文测试数据集（`test.txt`），其中每一行为一句中文文本，需要同学提交模型做出的对应翻译结果，助教将对于大家的提交结果统一机器评测，并给出分数。\n",
    "\n",
    "### 改进方向\n",
    "\n",
    "初级改进：\n",
    "- 将RNN模型替换成GRU或者LSTM\n",
    "- 使用双向的encoder获得更好的源语言表示\n",
    "- 对于现有超参数进行调优，这里建议划分出一个开发集，在开发集上进行grid search，并且在报告中汇报开发集结果\n",
    "- 引入更多的训练语料（如果尝试复杂模型，更多的训练数据将非常关键）\n",
    "\n",
    "进阶改进：\n",
    "- 使用注意力机制（注意力机制是一个很重要的NMT技术，建议大家优先进行这方面的尝试，具体有许多种变体，可以参考这个[综述](https://nlp.stanford.edu/pubs/emnlp15_attn.pdf)）\n",
    "- 在Encoder部分，使用了字级别的中文输入，可以考虑加入分词的结果，并且将Encoder的词向量替换为预训练过的词向量，获得更好的性能\n",
    "\n",
    "复杂改进：\n",
    "- 使用beam search的技术来帮助更好的解码，对于beam-width进行调优\n",
    "- 将RNN替换为Transformer模型，以及最新的改进变体"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_CUDA: True\n"
     ]
    }
   ],
   "source": [
    "print('USE_CUDA: %s' % USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTATION = True    # 是否分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本预处理\n",
    "\n",
    "丢弃除了中文、字母和常用标点之外的符号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5.!?，。？]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建词表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入三个特殊的Token:\n",
    "\n",
    "1. `SOS`, \"Start of sentence”，标识句子开始\n",
    "2. `EOS`, “End of sentence”，表示句子结束\n",
    "3. `UNK`, \"Unknown Token\"，标识未登录词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK_token = 2\n",
    "\n",
    "class Lang(object):\n",
    "    \"\"\"\n",
    "    词表Vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", '2': 'UNK'}\n",
    "        self.n_words = 3 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        if self.name == 'cn':\n",
    "            words = list(jieba.cut(sentence)) if SEGMENTATION else sentence    \n",
    "            for word in words:\n",
    "                self.index_word(word)\n",
    "        else:\n",
    "            words = sentence.split(' ')\n",
    "            for word in words:\n",
    "                self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取平行语料，并进行清理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('%s-%s.txt' % (lang1, lang2)).read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备数据集\n",
    "\n",
    "样例为了加快训练，只保留了不长于10个单词的句对，真正实验中将更多数据考虑进来可能获得更好的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理数据的全过程：\n",
    "\n",
    "- 读取数据，每一行分别处理，将其转换成句对\n",
    "- 对于文本进行处理，过滤无用符号\n",
    "- 根据已有文本对于单词进行编号，构建符号到编号的映射\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 90000 sentence pairs\n",
      "Trimmed to 68898 sentence pairs\n",
      "Indexing words...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.427 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['请过目 页的地图。', 'please look over the map on page .']\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('cn', 'eng', False)\n",
    "\n",
    "# Print an example pair\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从数据集中sample出200条数据作为验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_test_dataset(size=100):\n",
    "\n",
    "    with open('cn-eng-test.txt', 'w+') as f:\n",
    "        f.write('\\n'.join(['\\t'.join(pair) for pair in random.sample(pairs, k=size)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_test_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将文本数据转换为张量\n",
    "\n",
    "为了训练，我们需要将句子变成神经网络可以理解的东西（数字）。每个句子将被分解成单词，然后变成张量，其中每个单词都被索引替换（来自之前的Lang索引）。在创建这些张量时，我们还将附加EOS令牌以表示该句子已结束。\n",
    "\n",
    "![](https://i.imgur.com/LzocpGH.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    根据词表，将句子转化成索引列表。\n",
    "\n",
    "    :reutrn list，e.g. [1, 2, 3, 4]\n",
    "    \"\"\"\n",
    "    if lang.name == 'cn':\n",
    "        words = list(jieba.cut(sentence)) if SEGMENTATION else sentence\n",
    "        return [lang.word2index[word] if word in lang.word2index else UNK_token for word in words ]\n",
    "    else:\n",
    "        words = sentence.split(' ')\n",
    "        return [lang.word2index[word] if word in lang.word2index else UNK_token for word in words]\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    将句子转换成Tensor.\n",
    "    \n",
    "    :return Tensor, shape(n, 1)\n",
    "    \"\"\"\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = torch.LongTensor(indexes).view(-1, 1)\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    \"\"\"\n",
    "    将平行语料对转化成Tensors.\n",
    "    \n",
    "    :return (input_tensor, output_tensor)\n",
    "    \"\"\"\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    target_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair: ['这就是昨天linda提到的那个车。', 'this is the car linda mentioned yesterday .']\n",
      "input_tensor shape: torch.Size([10, 1]), output_tensor shap: torch.Size([9, 1])\n",
      "input_tensor: tensor([[  189],\n",
      "        [  167],\n",
      "        [ 1085],\n",
      "        [16353],\n",
      "        [ 2632],\n",
      "        [   47],\n",
      "        [  427],\n",
      "        [  803],\n",
      "        [   12],\n",
      "        [    1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "print('pair: %s' % pair)\n",
    "\n",
    "input_tensor, target_tensor = variables_from_pair(pair)\n",
    "print('input_tensor shape: %s, output_tensor shap: %s' % (input_tensor.shape, target_tensor.shape))\n",
    "print('input_tensor: %s' % input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 组件模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"编码器\"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        :param input_size, 输入词表大\n",
    "        :param hidden_size, Embedding维度大小，RNN hidden大小\n",
    "        :param n_layers, RNN层数\n",
    "        \"\"\"\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param word_inputs, 输入词序列 shape(n, 1)\n",
    "        :param hidden, 隐层 shape(seq_len*n_layers, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.n_layers, 1, self.hidden_size)\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"解码器\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden):\n",
    "        # Note: we run this one step at a time        \n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        rnn_output, hidden = self.rnn(word_embedded, last_hidden)\n",
    "\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        output = F.log_softmax(self.out(rnn_output))\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练\n",
    "\n",
    "## 一次训练迭代\n",
    "\n",
    "为了训练，我们首先通过编码器逐字运行输入语句，并跟踪每个输出和最新的隐藏状态。接下来，为解码器提供解码器的最后一个隐藏状态作为其第一隐藏状态，并向其提供`<SOS>`作为其第一输入。从那里开始，我们迭代地预测来自解码器的下一个单词。\n",
    "    \n",
    "### Teacher Forcing 和 Scheduled Sampling\n",
    "\n",
    "\"Teacher Forcing\"指的是每次都基于完全准确的上文进行解码，这样训练模型收敛很快，但是会造成实际场景和训练场景有较大差别，因为实际场景上文也都是模型预测的，可能不准确，具体细节可参考[论文](http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf)。\n",
    "\n",
    "观察Teacher Forcing的网络的输出，我们可以看到该网络语法连贯，但是偏离正确的翻译。可以将其为学会了如何听老师的指示，而未学习如何独自冒险。\n",
    "\n",
    "解决强迫教师问题的方法称为“计划抽样”（[Scheduled Sampling](https://arxiv.org/abs/1506.03099)），它在训练时仅在使用目标值和预测值之间进行切换。我们将在训练时随机选择,有时我们将使用真实目标作为输入（忽略解码器的输出），有时我们将使用解码器的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, \n",
    "          encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, \n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = torch.LongTensor([[SOS_token]])\n",
    "    decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = torch.LongTensor([[ni]]) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是用于辅助输出训练情况的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout_p = 0.05\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers)\n",
    "decoder = DecoderRNN(hidden_size, output_lang.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下设置变量用于绘制图标和跟踪进度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Configuring training\n",
    "n_epochs = 50000\n",
    "plot_every = 200\n",
    "print_every = 1000\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要进行实际训练，我们会多次调用训练函数，并在进行过程中打印中间信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:57: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/50000, 0m 10s (- 8m 21s), 5.0653\n",
      "Epoch 2000/50000, 0m 20s (- 8m 16s), 4.8452\n",
      "Epoch 3000/50000, 0m 31s (- 8m 8s), 4.6472\n",
      "Epoch 4000/50000, 0m 41s (- 7m 59s), 4.5257\n",
      "Epoch 5000/50000, 0m 52s (- 7m 50s), 4.4661\n",
      "Epoch 6000/50000, 1m 2s (- 7m 41s), 4.4569\n",
      "Epoch 7000/50000, 1m 13s (- 7m 31s), 4.4462\n",
      "Epoch 8000/50000, 1m 23s (- 7m 20s), 4.3573\n",
      "Epoch 9000/50000, 1m 34s (- 7m 11s), 4.3778\n",
      "Epoch 10000/50000, 1m 45s (- 7m 0s), 4.2946\n",
      "Epoch 11000/50000, 1m 55s (- 6m 50s), 4.2235\n",
      "Epoch 12000/50000, 2m 6s (- 6m 40s), 4.3393\n",
      "Epoch 13000/50000, 2m 16s (- 6m 29s), 4.2633\n",
      "Epoch 14000/50000, 2m 27s (- 6m 19s), 4.2856\n",
      "Epoch 15000/50000, 2m 38s (- 6m 8s), 4.2243\n",
      "Epoch 16000/50000, 2m 48s (- 5m 58s), 4.1897\n",
      "Epoch 17000/50000, 3m 0s (- 5m 49s), 4.1881\n",
      "Epoch 18000/50000, 3m 10s (- 5m 39s), 4.2410\n",
      "Epoch 19000/50000, 3m 21s (- 5m 28s), 4.1906\n",
      "Epoch 20000/50000, 3m 32s (- 5m 18s), 4.2198\n",
      "Epoch 21000/50000, 3m 45s (- 5m 11s), 4.1450\n",
      "Epoch 22000/50000, 4m 5s (- 5m 13s), 4.2009\n",
      "Epoch 23000/50000, 4m 26s (- 5m 13s), 4.2141\n",
      "Epoch 24000/50000, 4m 47s (- 5m 11s), 4.1105\n",
      "Epoch 25000/50000, 5m 8s (- 5m 8s), 4.2169\n",
      "Epoch 26000/50000, 5m 29s (- 5m 4s), 4.1842\n",
      "Epoch 27000/50000, 5m 49s (- 4m 57s), 4.1780\n",
      "Epoch 28000/50000, 6m 9s (- 4m 50s), 4.1298\n",
      "Epoch 29000/50000, 6m 30s (- 4m 42s), 4.1811\n",
      "Epoch 30000/50000, 6m 51s (- 4m 34s), 4.1206\n",
      "Epoch 31000/50000, 7m 11s (- 4m 24s), 4.1240\n",
      "Epoch 32000/50000, 7m 32s (- 4m 14s), 4.1673\n",
      "Epoch 33000/50000, 7m 52s (- 4m 3s), 4.0896\n",
      "Epoch 34000/50000, 8m 13s (- 3m 52s), 4.0465\n",
      "Epoch 35000/50000, 8m 33s (- 3m 40s), 4.0688\n",
      "Epoch 36000/50000, 8m 54s (- 3m 27s), 4.0674\n",
      "Epoch 37000/50000, 9m 14s (- 3m 14s), 4.1230\n",
      "Epoch 38000/50000, 9m 35s (- 3m 1s), 4.0054\n",
      "Epoch 39000/50000, 9m 56s (- 2m 48s), 4.0839\n",
      "Epoch 40000/50000, 10m 16s (- 2m 34s), 4.0391\n",
      "Epoch 41000/50000, 10m 37s (- 2m 19s), 3.9999\n",
      "Epoch 42000/50000, 10m 58s (- 2m 5s), 3.9630\n",
      "Epoch 43000/50000, 11m 18s (- 1m 50s), 3.9471\n",
      "Epoch 44000/50000, 11m 39s (- 1m 35s), 4.0421\n",
      "Epoch 45000/50000, 12m 0s (- 1m 20s), 3.9910\n",
      "Epoch 46000/50000, 12m 20s (- 1m 4s), 3.9733\n",
      "Epoch 47000/50000, 12m 41s (- 0m 48s), 3.9726\n",
      "Epoch 48000/50000, 13m 1s (- 0m 32s), 4.0049\n",
      "Epoch 49000/50000, 13m 22s (- 0m 16s), 3.9429\n",
      "Epoch 50000/50000, 13m 43s (- 0m 0s), 4.0223\n"
     ]
    }
   ],
   "source": [
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    training_pair = variables_from_pair(random.choice(pairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = 'Epoch %d/%d, %s, %.4f' % (epoch, n_epochs, time_since(start, epoch / n_epochs), print_loss_avg)\n",
    "        print(print_summary)\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制训练loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), './model_storage/baseline/encoder.pkl')\n",
    "torch.save(decoder.state_dict(), './model_storage/baseline/decoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variable_from_sentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = torch.LongTensor([[SOS_token]]) # SOS\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni.item()])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = torch.LongTensor([[ni]])\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机选取一个句子进行验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 汤姆知道我不喜欢他。\n",
      "= tom knows that i don t like him .\n",
      "< tom will be a . . <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "\n",
    "# 读取测试数据集\n",
    "with open('cn-eng-test.txt') as f:\n",
    "    lines = f.read().strip().split('\\n')\n",
    "    \n",
    "    test_pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "\n",
    "\n",
    "test_pairs_dict = collections.defaultdict(lambda : [])\n",
    "\n",
    "for pair in test_pairs:\n",
    "    test_pairs_dict[pair[0]].append(pair[1].split(' '))\n",
    "\n",
    "\n",
    "def evaluate_bleu_score():\n",
    "    candicates = []\n",
    "    references = []\n",
    "\n",
    "    for i, pair in enumerate(test_pairs_dict.items(), start=1):\n",
    "        candicate = evaluate(pair[0])\n",
    "        if candicate[-1] == '<EOS>':\n",
    "            candicate.pop(-1)\n",
    "        candicates.append(candicate)\n",
    "        references.append(pair[1])\n",
    "    \n",
    "    score = bleu_score(candicates, references)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset bleu score: 0.026368507232568898\n"
     ]
    }
   ],
   "source": [
    "print('test dataset bleu score: %s' % evaluate_bleu_score())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "536.733px",
    "left": "1211.8px",
    "right": "20px",
    "top": "120px",
    "width": "360.014px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
