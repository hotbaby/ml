{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq模型——机器翻译\n",
    "\n",
    "初级改进：\n",
    "\n",
    "1. 用GRU替换RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_CUDA: True\n"
     ]
    }
   ],
   "source": [
    "print('USE_CUDA: %s' % USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTATION = False    # 是否分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本预处理\n",
    "\n",
    "丢弃除了中文、字母和常用标点之外的符号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5.!?，。？]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建词表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入三个特殊的Token:\n",
    "\n",
    "1. `SOS`, \"Start of sentence”，标识句子开始\n",
    "2. `EOS`, “End of sentence”，表示句子结束\n",
    "3. `UNK`, \"Unknown Token\"，标识未登录词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK_token = 2\n",
    "\n",
    "class Lang(object):\n",
    "    \"\"\"\n",
    "    词表Vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", '2': 'UNK'}\n",
    "        self.n_words = 3 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        if self.name == 'cn':\n",
    "            words = list(jieba.cut(sentence)) if SEGMENTATION else sentence    \n",
    "            for word in words:\n",
    "                self.index_word(word)\n",
    "        else:\n",
    "            words = sentence.split(' ')\n",
    "            for word in words:\n",
    "                self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取平行语料，并进行清理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('%s-%s.txt' % (lang1, lang2)).read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备数据集\n",
    "\n",
    "样例为了加快训练，只保留了不长于10个单词的句对，真正实验中将更多数据考虑进来可能获得更好的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理数据的全过程：\n",
    "\n",
    "- 读取数据，每一行分别处理，将其转换成句对\n",
    "- 对于文本进行处理，过滤无用符号\n",
    "- 根据已有文本对于单词进行编号，构建符号到编号的映射\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 90000 sentence pairs\n",
      "Trimmed to 68898 sentence pairs\n",
      "Indexing words...\n",
      "['无法靠近敌人', 'we can t get close to the enemy .']\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('cn', 'eng', False)\n",
    "\n",
    "# Print an example pair\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从数据集中sample出200条数据作为验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_test_dataset(size=100):\n",
    "\n",
    "    with open('cn-eng-test.txt', 'w+') as f:\n",
    "        f.write('\\n'.join(['\\t'.join(pair) for pair in random.sample(pairs, k=size)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_test_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将文本数据转换为张量\n",
    "\n",
    "为了训练，我们需要将句子变成神经网络可以理解的东西（数字）。每个句子将被分解成单词，然后变成张量，其中每个单词都被索引替换（来自之前的Lang索引）。在创建这些张量时，我们还将附加EOS令牌以表示该句子已结束。\n",
    "\n",
    "![](https://i.imgur.com/LzocpGH.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    根据词表，将句子转化成索引列表。\n",
    "\n",
    "    :reutrn list，e.g. [1, 2, 3, 4]\n",
    "    \"\"\"\n",
    "    if lang.name == 'cn':\n",
    "        words = list(jieba.cut(sentence)) if SEGMENTATION else sentence\n",
    "        return [lang.word2index[word] if word in lang.word2index else UNK_token for word in words ]\n",
    "    else:\n",
    "        words = sentence.split(' ')\n",
    "        return [lang.word2index[word] if word in lang.word2index else UNK_token for word in words]\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    将句子转换成Tensor.\n",
    "    \n",
    "    :return Tensor, shape(n, 1)\n",
    "    \"\"\"\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = torch.LongTensor(indexes).view(-1, 1)\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    \"\"\"\n",
    "    将平行语料对转化成Tensors.\n",
    "    \n",
    "    :return (input_tensor, output_tensor)\n",
    "    \"\"\"\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    target_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair: ['你有多高？', 'how tall are you ?']\n",
      "input_tensor shape: torch.Size([6, 1]), output_tensor shap: torch.Size([6, 1])\n",
      "input_tensor: tensor([[ 14],\n",
      "        [ 61],\n",
      "        [178],\n",
      "        [778],\n",
      "        [ 20],\n",
      "        [  1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "print('pair: %s' % pair)\n",
    "\n",
    "input_tensor, target_tensor = variables_from_pair(pair)\n",
    "print('input_tensor shape: %s, output_tensor shap: %s' % (input_tensor.shape, target_tensor.shape))\n",
    "print('input_tensor: %s' % input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入依赖包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class EncoderGRU(nn.Module):\n",
    "    \"\"\"GRU 编码器\"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, bidirectional=False):\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        :param input_size, 输入词表大\n",
    "        :param hidden_size, Embedding维度大小，RNN hidden大小\n",
    "        :param n_layers, RNN层数\n",
    "        \"\"\"\n",
    "        super(EncoderGRU, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        # 用GRU替换RNN\n",
    "        # self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param word_inputs, 输入序列 shape(n, 1)\n",
    "        :param hidden, 隐层 shape(seq_len*n_layers, batch_size, hidden_size)\n",
    "        :return output(seq_len, batch, num_directions*hidden_size),\n",
    "                hidden(num_layers*num_directions, hidden_size)\n",
    "        \"\"\"\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        num_directions = 2 if self.bidirectional else 1\n",
    "        hidden = torch.zeros(self.n_layers*num_directions, 1, self.hidden_size)\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DecoderGRU(nn.Module):\n",
    "    \"\"\"GRU 解码器\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, bidirectional=False):\n",
    "        super(DecoderGRU, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "\n",
    "        # 使用GRU替换RNN\n",
    "        # self.rnn = nn.RNN(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout_p, \n",
    "                          bidirectional=bidirectional)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden):\n",
    "        # Note: we run this one step at a time        \n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        rnn_output, hidden = self.rnn(word_embedded, last_hidden)\n",
    "\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        output = F.log_softmax(self.out(rnn_output))\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "为了训练，我们首先通过编码器逐字运行输入语句，并跟踪每个输出和最新的隐藏状态。接下来，为解码器提供解码器的最后一个隐藏状态作为其第一隐藏状态，并向其提供`<SOS>`作为其第一输入。从那里开始，我们迭代地预测来自解码器的下一个单词。\n",
    "    \n",
    "**Teacher Forcing 和 Scheduled Sampling**\n",
    "\n",
    "\"Teacher Forcing\"指的是每次都基于完全准确的上文进行解码，这样训练模型收敛很快，但是会造成实际场景和训练场景有较大差别，因为实际场景上文也都是模型预测的，可能不准确，具体细节可参考[论文](http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf)。\n",
    "\n",
    "观察Teacher Forcing的网络的输出，我们可以看到该网络语法连贯，但是偏离正确的翻译。可以将其为学会了如何听老师的指示，而未学习如何独自冒险。\n",
    "\n",
    "解决强迫教师问题的方法称为“计划抽样”（[Scheduled Sampling](https://arxiv.org/abs/1506.03099)），它在训练时仅在使用目标值和预测值之间进行切换。我们将在训练时随机选择,有时我们将使用真实目标作为输入（忽略解码器的输出），有时我们将使用解码器的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, \n",
    "          encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, \n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = torch.LongTensor([[SOS_token]])\n",
    "    decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = torch.LongTensor([[ni]]) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是用于辅助输出训练情况的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行训练GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:57: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/150000, 0m 23s (- 57m 20s), 4.9935\n",
      "Epoch 2000/150000, 0m 47s (- 58m 56s), 4.7548\n",
      "Epoch 3000/150000, 1m 12s (- 59m 34s), 4.5939\n",
      "Epoch 4000/150000, 1m 38s (- 59m 53s), 4.5261\n",
      "Epoch 5000/150000, 2m 4s (- 60m 7s), 4.3890\n",
      "Epoch 6000/150000, 2m 29s (- 59m 57s), 4.3530\n",
      "Epoch 7000/150000, 2m 55s (- 59m 52s), 4.2718\n",
      "Epoch 8000/150000, 3m 21s (- 59m 39s), 4.1538\n",
      "Epoch 9000/150000, 3m 46s (- 59m 11s), 4.0796\n",
      "Epoch 10000/150000, 4m 12s (- 58m 51s), 4.0986\n",
      "Epoch 11000/150000, 4m 37s (- 58m 30s), 4.0350\n",
      "Epoch 12000/150000, 5m 3s (- 58m 10s), 4.0175\n",
      "Epoch 13000/150000, 5m 29s (- 57m 48s), 3.9527\n",
      "Epoch 14000/150000, 5m 54s (- 57m 26s), 3.9726\n",
      "Epoch 15000/150000, 6m 20s (- 57m 5s), 3.9263\n",
      "Epoch 16000/150000, 6m 46s (- 56m 44s), 3.8681\n",
      "Epoch 17000/150000, 7m 12s (- 56m 24s), 3.7962\n",
      "Epoch 18000/150000, 7m 38s (- 55m 59s), 3.7925\n",
      "Epoch 19000/150000, 8m 3s (- 55m 33s), 3.7100\n",
      "Epoch 20000/150000, 8m 29s (- 55m 12s), 3.7595\n",
      "Epoch 21000/150000, 8m 55s (- 54m 49s), 3.6541\n",
      "Epoch 22000/150000, 9m 21s (- 54m 26s), 3.6576\n",
      "Epoch 23000/150000, 9m 46s (- 53m 58s), 3.5521\n",
      "Epoch 24000/150000, 10m 12s (- 53m 34s), 3.5099\n",
      "Epoch 25000/150000, 10m 37s (- 53m 9s), 3.5441\n",
      "Epoch 26000/150000, 11m 3s (- 52m 44s), 3.5723\n",
      "Epoch 27000/150000, 11m 29s (- 52m 22s), 3.5088\n",
      "Epoch 28000/150000, 11m 54s (- 51m 54s), 3.5116\n",
      "Epoch 29000/150000, 12m 19s (- 51m 26s), 3.4495\n",
      "Epoch 30000/150000, 12m 45s (- 51m 3s), 3.4753\n",
      "Epoch 31000/150000, 13m 11s (- 50m 39s), 3.4560\n",
      "Epoch 32000/150000, 13m 37s (- 50m 13s), 3.3502\n",
      "Epoch 33000/150000, 14m 3s (- 49m 49s), 3.2900\n",
      "Epoch 34000/150000, 14m 29s (- 49m 25s), 3.2871\n",
      "Epoch 35000/150000, 14m 54s (- 48m 59s), 3.3147\n",
      "Epoch 36000/150000, 15m 20s (- 48m 34s), 3.3087\n",
      "Epoch 37000/150000, 15m 45s (- 48m 8s), 3.2488\n",
      "Epoch 38000/150000, 16m 11s (- 47m 42s), 3.2916\n",
      "Epoch 39000/150000, 16m 37s (- 47m 17s), 3.2697\n",
      "Epoch 40000/150000, 17m 2s (- 46m 51s), 3.2947\n",
      "Epoch 41000/150000, 17m 27s (- 46m 25s), 3.2563\n",
      "Epoch 42000/150000, 17m 53s (- 46m 0s), 3.1986\n",
      "Epoch 43000/150000, 18m 18s (- 45m 34s), 3.1748\n",
      "Epoch 44000/150000, 18m 44s (- 45m 9s), 3.1781\n",
      "Epoch 45000/150000, 19m 10s (- 44m 44s), 3.0931\n",
      "Epoch 46000/150000, 19m 36s (- 44m 19s), 3.1312\n",
      "Epoch 47000/150000, 20m 1s (- 43m 53s), 3.1000\n",
      "Epoch 48000/150000, 20m 27s (- 43m 28s), 3.0854\n",
      "Epoch 49000/150000, 20m 53s (- 43m 3s), 3.0953\n",
      "Epoch 50000/150000, 21m 18s (- 42m 36s), 2.9635\n",
      "Epoch 51000/150000, 21m 44s (- 42m 12s), 3.0596\n",
      "Epoch 52000/150000, 22m 10s (- 41m 47s), 3.0146\n",
      "Epoch 53000/150000, 22m 36s (- 41m 22s), 3.0599\n",
      "Epoch 54000/150000, 23m 2s (- 40m 58s), 2.9834\n",
      "Epoch 55000/150000, 23m 28s (- 40m 32s), 3.0128\n",
      "Epoch 56000/150000, 23m 54s (- 40m 7s), 2.9477\n",
      "Epoch 57000/150000, 24m 19s (- 39m 41s), 2.9139\n",
      "Epoch 58000/150000, 24m 46s (- 39m 17s), 2.9072\n",
      "Epoch 59000/150000, 25m 11s (- 38m 51s), 3.0930\n",
      "Epoch 60000/150000, 25m 37s (- 38m 26s), 2.9762\n",
      "Epoch 61000/150000, 26m 3s (- 38m 1s), 2.8658\n",
      "Epoch 62000/150000, 26m 29s (- 37m 36s), 2.9086\n",
      "Epoch 63000/150000, 26m 54s (- 37m 9s), 2.7426\n",
      "Epoch 64000/150000, 27m 20s (- 36m 44s), 2.7953\n",
      "Epoch 65000/150000, 27m 46s (- 36m 19s), 2.7891\n",
      "Epoch 66000/150000, 28m 12s (- 35m 54s), 2.7909\n",
      "Epoch 67000/150000, 28m 38s (- 35m 28s), 2.7789\n",
      "Epoch 68000/150000, 29m 4s (- 35m 3s), 2.7696\n",
      "Epoch 69000/150000, 29m 31s (- 34m 39s), 2.7839\n",
      "Epoch 70000/150000, 29m 57s (- 34m 13s), 2.6962\n",
      "Epoch 71000/150000, 30m 22s (- 33m 48s), 2.7345\n",
      "Epoch 72000/150000, 30m 48s (- 33m 22s), 2.7194\n",
      "Epoch 73000/150000, 31m 14s (- 32m 57s), 2.6974\n",
      "Epoch 74000/150000, 31m 40s (- 32m 31s), 2.7091\n",
      "Epoch 75000/150000, 32m 6s (- 32m 6s), 2.6634\n",
      "Epoch 76000/150000, 32m 31s (- 31m 40s), 2.6425\n",
      "Epoch 77000/150000, 32m 57s (- 31m 14s), 2.6853\n",
      "Epoch 78000/150000, 33m 23s (- 30m 49s), 2.6291\n",
      "Epoch 79000/150000, 33m 50s (- 30m 24s), 2.6765\n",
      "Epoch 80000/150000, 34m 16s (- 29m 59s), 2.5974\n",
      "Epoch 81000/150000, 34m 43s (- 29m 34s), 2.5509\n",
      "Epoch 82000/150000, 35m 9s (- 29m 8s), 2.5047\n",
      "Epoch 83000/150000, 35m 34s (- 28m 43s), 2.5718\n",
      "Epoch 84000/150000, 36m 0s (- 28m 17s), 2.5771\n",
      "Epoch 85000/150000, 36m 26s (- 27m 51s), 2.5656\n",
      "Epoch 86000/150000, 36m 52s (- 27m 26s), 2.5538\n",
      "Epoch 87000/150000, 37m 18s (- 27m 0s), 2.5723\n",
      "Epoch 88000/150000, 37m 44s (- 26m 35s), 2.5959\n",
      "Epoch 89000/150000, 38m 9s (- 26m 9s), 2.4974\n",
      "Epoch 90000/150000, 38m 35s (- 25m 43s), 2.4873\n",
      "Epoch 91000/150000, 39m 1s (- 25m 18s), 2.5019\n",
      "Epoch 92000/150000, 39m 27s (- 24m 52s), 2.4629\n",
      "Epoch 93000/150000, 39m 52s (- 24m 26s), 2.4034\n",
      "Epoch 94000/150000, 40m 19s (- 24m 1s), 2.4393\n",
      "Epoch 95000/150000, 40m 45s (- 23m 35s), 2.4259\n",
      "Epoch 96000/150000, 41m 12s (- 23m 10s), 2.4452\n",
      "Epoch 97000/150000, 41m 38s (- 22m 45s), 2.4679\n",
      "Epoch 98000/150000, 42m 4s (- 22m 19s), 2.3869\n",
      "Epoch 99000/150000, 42m 30s (- 21m 54s), 2.4833\n",
      "Epoch 100000/150000, 42m 56s (- 21m 28s), 2.3699\n",
      "Epoch 101000/150000, 43m 23s (- 21m 2s), 2.4063\n",
      "Epoch 102000/150000, 43m 49s (- 20m 37s), 2.4889\n",
      "Epoch 103000/150000, 44m 15s (- 20m 11s), 2.3415\n",
      "Epoch 104000/150000, 44m 41s (- 19m 45s), 2.4049\n",
      "Epoch 105000/150000, 45m 7s (- 19m 20s), 2.3698\n",
      "Epoch 106000/150000, 45m 32s (- 18m 54s), 2.3608\n",
      "Epoch 107000/150000, 45m 58s (- 18m 28s), 2.3280\n",
      "Epoch 108000/150000, 46m 24s (- 18m 2s), 2.3617\n",
      "Epoch 109000/150000, 46m 49s (- 17m 36s), 2.3551\n",
      "Epoch 110000/150000, 47m 14s (- 17m 10s), 2.3218\n",
      "Epoch 111000/150000, 47m 40s (- 16m 45s), 2.3374\n",
      "Epoch 112000/150000, 48m 6s (- 16m 19s), 2.2554\n",
      "Epoch 113000/150000, 48m 32s (- 15m 53s), 2.3006\n",
      "Epoch 114000/150000, 48m 59s (- 15m 28s), 2.3787\n",
      "Epoch 115000/150000, 49m 25s (- 15m 2s), 2.2496\n",
      "Epoch 116000/150000, 49m 52s (- 14m 37s), 2.3416\n",
      "Epoch 117000/150000, 50m 20s (- 14m 11s), 2.3058\n",
      "Epoch 118000/150000, 50m 47s (- 13m 46s), 2.2366\n",
      "Epoch 119000/150000, 51m 13s (- 13m 20s), 2.2648\n",
      "Epoch 120000/150000, 51m 39s (- 12m 54s), 2.3138\n",
      "Epoch 121000/150000, 52m 5s (- 12m 29s), 2.2559\n",
      "Epoch 122000/150000, 52m 31s (- 12m 3s), 2.1706\n",
      "Epoch 123000/150000, 52m 57s (- 11m 37s), 2.2011\n",
      "Epoch 124000/150000, 53m 23s (- 11m 11s), 2.1954\n",
      "Epoch 125000/150000, 53m 49s (- 10m 45s), 2.2546\n",
      "Epoch 126000/150000, 54m 16s (- 10m 20s), 2.2142\n",
      "Epoch 127000/150000, 54m 42s (- 9m 54s), 2.2672\n",
      "Epoch 128000/150000, 55m 8s (- 9m 28s), 2.2519\n",
      "Epoch 129000/150000, 55m 33s (- 9m 2s), 2.3006\n",
      "Epoch 130000/150000, 56m 0s (- 8m 36s), 2.2191\n",
      "Epoch 131000/150000, 56m 26s (- 8m 11s), 2.2514\n",
      "Epoch 132000/150000, 56m 51s (- 7m 45s), 2.1762\n",
      "Epoch 133000/150000, 57m 17s (- 7m 19s), 2.0977\n",
      "Epoch 134000/150000, 57m 43s (- 6m 53s), 2.1900\n",
      "Epoch 135000/150000, 58m 9s (- 6m 27s), 2.1398\n",
      "Epoch 136000/150000, 58m 35s (- 6m 1s), 2.2385\n",
      "Epoch 137000/150000, 59m 1s (- 5m 36s), 2.1219\n",
      "Epoch 138000/150000, 59m 27s (- 5m 10s), 2.1780\n",
      "Epoch 139000/150000, 59m 53s (- 4m 44s), 2.1695\n",
      "Epoch 140000/150000, 60m 19s (- 4m 18s), 2.1014\n",
      "Epoch 141000/150000, 60m 45s (- 3m 52s), 2.0567\n",
      "Epoch 142000/150000, 61m 12s (- 3m 26s), 2.0661\n",
      "Epoch 143000/150000, 61m 39s (- 3m 1s), 2.1842\n",
      "Epoch 144000/150000, 62m 5s (- 2m 35s), 2.1268\n",
      "Epoch 145000/150000, 62m 32s (- 2m 9s), 2.1378\n",
      "Epoch 146000/150000, 62m 58s (- 1m 43s), 2.1680\n",
      "Epoch 147000/150000, 63m 24s (- 1m 17s), 2.1248\n",
      "Epoch 148000/150000, 63m 50s (- 0m 51s), 2.1469\n",
      "Epoch 149000/150000, 64m 16s (- 0m 25s), 2.0948\n",
      "Epoch 150000/150000, 64m 42s (- 0m 0s), 2.0227\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout_p = 0.05\n",
    "bidirectional = False\n",
    "n_epochs = 150000\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderGRU(input_lang.n_words, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "decoder = DecoderGRU(hidden_size, output_lang.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Configuring training\n",
    "plot_every = 200\n",
    "print_every = 1000\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every\n",
    "\n",
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    training_pair = variables_from_pair(random.choice(pairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, encoder, decoder, \n",
    "                 encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = 'Epoch %d/%d, %s, %.4f' % (epoch, n_epochs, time_since(start, epoch / n_epochs), \n",
    "                                                   print_loss_avg)\n",
    "        print(print_summary)\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**绘制训练loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variable_from_sentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = torch.LongTensor([[SOS_token]]) # SOS\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni.item()])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = torch.LongTensor([[ni]])\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机选取一个句子进行验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 這個不重要。\n",
      "= it s not important .\n",
      "< it s not important . <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'life is fun . <EOS>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(evaluate('人生是有趣的。'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机的验证只是一个简单的例子，为了能系统性的完成测试数据的翻译，这里仍需要实现一个新的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "\n",
    "# 读取测试数据集\n",
    "with open('cn-eng-test.txt') as f:\n",
    "    lines = f.read().strip().split('\\n')\n",
    "    \n",
    "    test_pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "\n",
    "\n",
    "test_pairs_dict = collections.defaultdict(lambda : [])\n",
    "\n",
    "for pair in test_pairs:\n",
    "    test_pairs_dict[pair[0]].append(pair[1].split(' '))\n",
    "\n",
    "\n",
    "def evaluate_bleu_score():\n",
    "    candicates = []\n",
    "    references = []\n",
    "\n",
    "    for i, pair in enumerate(test_pairs_dict.items(), start=1):\n",
    "        candicate = evaluate(pair[0])\n",
    "        if candicate[-1] == '<EOS>':\n",
    "            candicate.pop(-1)\n",
    "        candicates.append(candicate)\n",
    "        references.append(pair[1])\n",
    "    \n",
    "    score = bleu_score(candicates, references)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset bleu score: 0.3201033895496221\n"
     ]
    }
   ],
   "source": [
    "print('test dataset bleu score: %s' % evaluate_bleu_score())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 514.7443639999999,
   "position": {
    "height": "40px",
    "left": "1211.8px",
    "right": "20px",
    "top": "120px",
    "width": "360px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
