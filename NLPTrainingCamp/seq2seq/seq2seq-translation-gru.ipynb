{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq模型——机器翻译\n",
    "\n",
    "初级改进：\n",
    "\n",
    "1. 用GRU替换RNN\n",
    "2. 使用双向的GRU\n",
    "3. 超参调优\n",
    "4. 引入更多的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果使用GPU，则将下面的变量设为`True`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "print('CUDA available: %s' % torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据\n",
    "\n",
    "我们将读取目录下的`cn-eng.txt`文件，其中每一行是一个平行句对，例子如下：\n",
    "\n",
    "```\n",
    "我很冷。    I am cold.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对于单词进行编号\n",
    "\n",
    "这里引入了两个特殊符号，“SOS”即“Start of sentence”和“EOS”即“End of sentence”。他们会加到输入文本的两端，以控制解码过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang(object):\n",
    "    \"\"\"\n",
    "    词表Vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        if self.name == 'cn':    \n",
    "            for word in sentence:\n",
    "                self.index_word(word)\n",
    "        else:\n",
    "            for word in sentence.split(' '):\n",
    "                self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本预处理\n",
    "\n",
    "丢弃除了中文、字母和常用标点之外的符号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5.!?，。？]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取平行语料，并进行清理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    \"\"\"\n",
    "    读取语料数据.\n",
    "    :return (输入词表，输出词表，平行语料对)\n",
    "    \"\"\"\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('%s-%s.txt' % (lang1, lang2)).read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过滤句子\n",
    "\n",
    "样例为了加快训练，只保留了不长于10个单词的句对，真正实验中将更多数据考虑进来可能获得更好的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理数据的全过程：\n",
    "\n",
    "- 读取数据，每一行分别处理，将其转换成句对\n",
    "- 对于文本进行处理，过滤无用符号\n",
    "- 根据已有文本对于单词进行编号，构建符号到编号的映射\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 90000 sentence pairs\n",
      "Trimmed to 68898 sentence pairs\n",
      "Indexing words...\n",
      "['我买了台新电视机。', 'i bought a new television .']\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('cn', 'eng', False)\n",
    "\n",
    "# Print an example pair\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将文本数据转换为张量\n",
    "\n",
    "为了训练，我们需要将句子变成神经网络可以理解的东西（数字）。每个句子将被分解成单词，然后变成张量，其中每个单词都被索引替换（来自之前的Lang索引）。在创建这些张量时，我们还将附加EOS令牌以表示该句子已结束。\n",
    "\n",
    "![](https://i.imgur.com/LzocpGH.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    根据词表，将句子转化成索引列表。\n",
    "\n",
    "    :reutrn list，e.g. [1, 2, 3, 4]\n",
    "    \"\"\"\n",
    "    if lang.name == 'cn':\n",
    "        return [lang.word2index[word] for word in sentence]\n",
    "    else:\n",
    "        return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    将句子转换成Tensor.\n",
    "    \n",
    "    :return Tensor, shape(n, 1)\n",
    "    \"\"\"\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = torch.LongTensor(indexes).view(-1, 1)\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    \"\"\"\n",
    "    将平行语料对转化成Tensors.\n",
    "    \n",
    "    :return (input_tensor, output_tensor)\n",
    "    \"\"\"\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    target_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair: ['你是我的阳光。', 'you are my sunshine .']\n",
      "input_tensor shape: torch.Size([8, 1]), output_tensor shap: torch.Size([6, 1])\n",
      "input_tensor: tensor([[  13],\n",
      "        [  21],\n",
      "        [   2],\n",
      "        [  63],\n",
      "        [1736],\n",
      "        [ 303],\n",
      "        [  12],\n",
      "        [   1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "print('pair: %s' % pair)\n",
    "\n",
    "input_tensor, target_tensor = variables_from_pair(pair)\n",
    "print('input_tensor shape: %s, output_tensor shap: %s' % (input_tensor.shape, target_tensor.shape))\n",
    "print('input_tensor: %s' % input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class EncoderGRU(nn.Module):\n",
    "    \"\"\"GRU 编码器\"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, bidirectional=False):\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        :param input_size, 输入词表大\n",
    "        :param hidden_size, Embedding维度大小，RNN hidden大小\n",
    "        :param n_layers, RNN层数\n",
    "        \"\"\"\n",
    "        super(EncoderGRU, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        # 用GRU替换RNN\n",
    "        # self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param word_inputs, 输入序列 shape(n, 1)\n",
    "        :param hidden, 隐层 shape(seq_len*n_layers, batch_size, hidden_size)\n",
    "        :return output(seq_len, batch, num_directions*hidden_size),\n",
    "                hidden(num_layers*num_directions, hidden_size)\n",
    "        \"\"\"\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        num_directions = 2 if self.bidirectional else 1\n",
    "        hidden = torch.zeros(self.n_layers*num_directions, 1, self.hidden_size)\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DecoderGRU(nn.Module):\n",
    "    \"\"\"GRU 解码器\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, bidirectional=False):\n",
    "        super(DecoderGRU, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "\n",
    "        # 使用GRU替换RNN\n",
    "        # self.rnn = nn.RNN(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout_p, \n",
    "                          bidirectional=bidirectional)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden):\n",
    "        # Note: we run this one step at a time        \n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        rnn_output, hidden = self.rnn(word_embedded, last_hidden)\n",
    "\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        output = F.log_softmax(self.out(rnn_output))\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "为了训练，我们首先通过编码器逐字运行输入语句，并跟踪每个输出和最新的隐藏状态。接下来，为解码器提供解码器的最后一个隐藏状态作为其第一隐藏状态，并向其提供`<SOS>`作为其第一输入。从那里开始，我们迭代地预测来自解码器的下一个单词。\n",
    "    \n",
    "**Teacher Forcing 和 Scheduled Sampling**\n",
    "\n",
    "\"Teacher Forcing\"指的是每次都基于完全准确的上文进行解码，这样训练模型收敛很快，但是会造成实际场景和训练场景有较大差别，因为实际场景上文也都是模型预测的，可能不准确，具体细节可参考[论文](http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf)。\n",
    "\n",
    "观察Teacher Forcing的网络的输出，我们可以看到该网络语法连贯，但是偏离正确的翻译。可以将其为学会了如何听老师的指示，而未学习如何独自冒险。\n",
    "\n",
    "解决强迫教师问题的方法称为“计划抽样”（[Scheduled Sampling](https://arxiv.org/abs/1506.03099)），它在训练时仅在使用目标值和预测值之间进行切换。我们将在训练时随机选择,有时我们将使用真实目标作为输入（忽略解码器的输出），有时我们将使用解码器的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, \n",
    "          encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, \n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = torch.LongTensor([[SOS_token]])\n",
    "    decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = torch.LongTensor([[ni]]) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是用于辅助输出训练情况的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行训练GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:56: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:57: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/50000, 0m 23s (- 19m 5s), 5.0358\n",
      "Epoch 2000/50000, 0m 47s (- 19m 8s), 4.6858\n",
      "Epoch 3000/50000, 1m 12s (- 19m 1s), 4.6571\n",
      "Epoch 4000/50000, 1m 37s (- 18m 42s), 4.4514\n",
      "Epoch 5000/50000, 2m 3s (- 18m 31s), 4.4603\n",
      "Epoch 6000/50000, 2m 29s (- 18m 12s), 4.3405\n",
      "Epoch 7000/50000, 2m 54s (- 17m 54s), 4.2663\n",
      "Epoch 8000/50000, 3m 20s (- 17m 31s), 4.1600\n",
      "Epoch 9000/50000, 3m 46s (- 17m 10s), 4.0913\n",
      "Epoch 10000/50000, 4m 11s (- 16m 47s), 4.0169\n",
      "Epoch 11000/50000, 4m 38s (- 16m 26s), 4.0198\n",
      "Epoch 12000/50000, 5m 3s (- 16m 1s), 3.9076\n",
      "Epoch 13000/50000, 5m 29s (- 15m 38s), 3.9851\n",
      "Epoch 14000/50000, 5m 55s (- 15m 14s), 3.8893\n",
      "Epoch 15000/50000, 6m 21s (- 14m 50s), 3.8756\n",
      "Epoch 16000/50000, 6m 47s (- 14m 26s), 3.7621\n",
      "Epoch 17000/50000, 7m 13s (- 14m 1s), 3.7752\n",
      "Epoch 18000/50000, 7m 38s (- 13m 35s), 3.7189\n",
      "Epoch 19000/50000, 8m 4s (- 13m 10s), 3.7053\n",
      "Epoch 20000/50000, 8m 30s (- 12m 45s), 3.7083\n",
      "Epoch 21000/50000, 8m 56s (- 12m 20s), 3.7212\n",
      "Epoch 22000/50000, 9m 21s (- 11m 54s), 3.6053\n",
      "Epoch 23000/50000, 9m 47s (- 11m 29s), 3.5744\n",
      "Epoch 24000/50000, 10m 12s (- 11m 3s), 3.5951\n",
      "Epoch 25000/50000, 10m 38s (- 10m 38s), 3.5442\n",
      "Epoch 26000/50000, 11m 3s (- 10m 12s), 3.4623\n",
      "Epoch 27000/50000, 11m 29s (- 9m 47s), 3.4888\n",
      "Epoch 28000/50000, 11m 55s (- 9m 21s), 3.4453\n",
      "Epoch 29000/50000, 12m 20s (- 8m 56s), 3.4687\n",
      "Epoch 30000/50000, 12m 45s (- 8m 30s), 3.3844\n",
      "Epoch 31000/50000, 13m 10s (- 8m 4s), 3.4201\n",
      "Epoch 32000/50000, 13m 36s (- 7m 39s), 3.3957\n",
      "Epoch 33000/50000, 14m 1s (- 7m 13s), 3.4322\n",
      "Epoch 34000/50000, 14m 27s (- 6m 48s), 3.2904\n",
      "Epoch 35000/50000, 14m 52s (- 6m 22s), 3.2798\n",
      "Epoch 36000/50000, 15m 18s (- 5m 57s), 3.2467\n",
      "Epoch 37000/50000, 15m 43s (- 5m 31s), 3.2407\n",
      "Epoch 38000/50000, 16m 9s (- 5m 6s), 3.2926\n",
      "Epoch 39000/50000, 16m 35s (- 4m 40s), 3.2100\n",
      "Epoch 40000/50000, 17m 0s (- 4m 15s), 3.3288\n",
      "Epoch 41000/50000, 17m 27s (- 3m 49s), 3.2374\n",
      "Epoch 42000/50000, 17m 53s (- 3m 24s), 3.2002\n",
      "Epoch 43000/50000, 18m 19s (- 2m 58s), 3.1235\n",
      "Epoch 44000/50000, 18m 44s (- 2m 33s), 3.0460\n",
      "Epoch 45000/50000, 19m 11s (- 2m 7s), 3.1093\n",
      "Epoch 46000/50000, 19m 36s (- 1m 42s), 3.1413\n",
      "Epoch 47000/50000, 20m 3s (- 1m 16s), 3.1104\n",
      "Epoch 48000/50000, 20m 29s (- 0m 51s), 3.0694\n",
      "Epoch 49000/50000, 20m 54s (- 0m 25s), 3.0213\n",
      "Epoch 50000/50000, 21m 20s (- 0m 0s), 2.9917\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout_p = 0.05\n",
    "bidirectional = False\n",
    "n_epochs = 50000\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderGRU(input_lang.n_words, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "decoder = DecoderGRU(hidden_size, output_lang.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Configuring training\n",
    "plot_every = 200\n",
    "print_every = 1000\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every\n",
    "\n",
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    training_pair = variables_from_pair(random.choice(pairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, encoder, decoder, \n",
    "                 encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = 'Epoch %d/%d, %s, %.4f' % (epoch, n_epochs, time_since(start, epoch / n_epochs), \n",
    "                                                   print_loss_avg)\n",
    "        print(print_summary)\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**绘制训练loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**保存模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), './model_storage/nmt_encoder_gru.pkl')\n",
    "torch.save(decoder.state_dict(), './model_storage/nmt_encoder_gru.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variable_from_sentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = torch.LongTensor([[SOS_token]]) # SOS\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni.item()])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = torch.LongTensor([[ni]])\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机选取一个句子进行验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 他明天出发去中国。\n",
      "= he leaves for china tomorrow .\n",
      "< he is going to go to . . <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'life is a . . <EOS>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(evaluate('人生是有趣的。'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机的验证只是一个简单的例子，为了能系统性的完成测试数据的翻译，这里仍需要实现一个新的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "pairs_dict = collections.defaultdict(lambda : [])\n",
    "\n",
    "for pair in pairs:\n",
    "    pairs_dict[pair[0]].append(pair[1].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "\n",
    "def evaluate_bleu_score(size=100):\n",
    "    candicates = []\n",
    "    references = []\n",
    "\n",
    "    for i, pair in enumerate(pairs_dict.items(), start=1):\n",
    "        candicate = evaluate(pair[0])\n",
    "        if candicate[-1] == '<EOS>':\n",
    "            candicate.pop(-1)\n",
    "        candicates.append(candicate)\n",
    "        references.append(pair[1])\n",
    "        \n",
    "        if size > 0 and size == i:\n",
    "            break\n",
    "    \n",
    "    score = bleu_score(candicates, references)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hotbaby/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16948330470367742"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bleu_score()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 514.7443639999999,
   "position": {
    "height": "40px",
    "left": "1211.8px",
    "right": "20px",
    "top": "120px",
    "width": "360px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
