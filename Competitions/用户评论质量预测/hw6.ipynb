{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用户评论质量预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 比赛介绍\n",
    "\n",
    "### 案例背景\n",
    "\n",
    "随着电商平台的兴起，以及疫情的持续影响，线上购物在我们的日常生活中扮演着越来越重要的角色。在进行线上商品挑选时，评论往往是我们十分关注的一个方面。然而目前电商网站的评论质量参差不齐，甚至有水军刷好评或者恶意差评的情况出现，严重影响了顾客的购物体验。因此，对于评论质量的预测成为电商平台越来越关注的话题，如果能自动对评论质量进行评估，就能根据预测结果避免展现低质量的评论。本案例中我们将基于集成学习的方法对 Amazon 现实场景中的评论质量进行预测。\n",
    "\n",
    "### 任务\n",
    "\n",
    "本案例中需要完成两种集成学习算法的实现（Bagging、AdaBoost.M1），其中基分类器要求使用 SVM 和决策树两种，因此，一共需要对比四组结果（[AUC](https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics) 作为评价指标）：\n",
    "\n",
    "* Bagging + SVM\n",
    "* Bagging + 决策树\n",
    "* AdaBoost.M1 + SVM\n",
    "* AdaBoost.M1 + 决策树\n",
    "\n",
    "注意集成学习的核心算法需要**手动进行实现**，基分类器可以调库。\n",
    "\n",
    "### 基本要求\n",
    "\n",
    "* 根据数据格式设计特征的表示\n",
    "* 汇报不同组合下得到的 AUC\n",
    "* 结合不同集成学习算法的特点分析结果之间的差异\n",
    "* （使用 sklearn 等第三方库的集成学习算法会酌情扣分）\n",
    "\n",
    "### 扩展要求\n",
    "\n",
    "* 尝试其他基分类器（如 k-NN、朴素贝叶斯）\n",
    "* 分析不同特征的影响\n",
    "* 分析集成学习算法参数的影响\n",
    "* 尝试各种方法提升排行榜上预测性能\n",
    "\n",
    "\n",
    "### 数据描述\n",
    "\n",
    "本次数据来源于 Amazon 电商平台，包含超过 50,000 条用户在购买商品后留下的评论，各列的含义如下：\n",
    "\n",
    "* reviewerID：用户 ID\n",
    "* asin：商品 ID\n",
    "* reviewText：英文评论文本\n",
    "* overall：用户对商品的打分（1-5）\n",
    "* votes_up：认为评论有用的点赞数（只在训练集出现）\n",
    "* votes_all：该评论得到的总评价数（只在训练集出现）\n",
    "* label：评论质量的 label，1 表示高质量，0 表示低质量（只在训练集出现）\n",
    "\n",
    "评论质量的 label 来自于其他用户对评论的 votes，votes_up/votes_all ≥ 0.9 的作为高质量评论。此外测试集包含一个额外的列`Id`，标识了每一个测试的样例。\n",
    "\n",
    "### 文件说明\n",
    "\n",
    "* train.csv：训练集\n",
    "* test.csv：测试集，用户和商品保证在训练集中出现过，没有关于 votes 和 label 的列\n",
    "\n",
    "文件使用 \\t 分隔，可以使用 pandas 进行读取：\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv('train.csv', sep='\\t')\n",
    "```\n",
    "\n",
    "### 提交格式\n",
    "\n",
    "提交文件需要对测试集中每一条评论给出预测为高质量的**概率**，每行包括一个`Id`（和测试集对应）以及预测的概率`Predicted`（0-1的浮点数），用逗号分隔。示例提交格式如下：\n",
    "\n",
    "```\n",
    "Id,Predicted\n",
    "0,0.9\n",
    "1,0.45\n",
    "2,0.78\n",
    "...\n",
    "```\n",
    "\n",
    "提交文件需要命名为`result.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import catboost\n",
    "import itertools\n",
    "from argparse import Namespace\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原始数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'data/train.csv'\n",
    "test_data_path = 'data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df = pd.read_csv(train_data_path, sep='\\t')\n",
    "raw_test_df = pd.read_csv(test_data_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_all</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7885</td>\n",
       "      <td>3901</td>\n",
       "      <td>First off, allow me to correct a common mistak...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52087</td>\n",
       "      <td>47978</td>\n",
       "      <td>I am really troubled by this Story and Enterta...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5701</td>\n",
       "      <td>3667</td>\n",
       "      <td>A near-perfect film version of a downright glo...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47191</td>\n",
       "      <td>40892</td>\n",
       "      <td>Keep your expectations low.  Really really low...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40957</td>\n",
       "      <td>15367</td>\n",
       "      <td>\"they dont make em like this no more...\"well.....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewerID   asin                                         reviewText  \\\n",
       "0        7885   3901  First off, allow me to correct a common mistak...   \n",
       "1       52087  47978  I am really troubled by this Story and Enterta...   \n",
       "2        5701   3667  A near-perfect film version of a downright glo...   \n",
       "3       47191  40892  Keep your expectations low.  Really really low...   \n",
       "4       40957  15367  \"they dont make em like this no more...\"well.....   \n",
       "\n",
       "   overall  votes_up  votes_all  label  \n",
       "0      5.0         6          7      0  \n",
       "1      3.0        99        134      0  \n",
       "2      4.0        14         14      1  \n",
       "3      1.0         4          7      0  \n",
       "4      5.0         3          6      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>82947</td>\n",
       "      <td>37386</td>\n",
       "      <td>I REALLY wanted this series but I am in SHOCK ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10154</td>\n",
       "      <td>23543</td>\n",
       "      <td>I have to say that this is a work of art for m...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5789</td>\n",
       "      <td>5724</td>\n",
       "      <td>Alien 3 is certainly the most controversal fil...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9198</td>\n",
       "      <td>5909</td>\n",
       "      <td>I love this film...preachy?  Well, of course i...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>33252</td>\n",
       "      <td>21214</td>\n",
       "      <td>Even though I previously bought the Gamera Dou...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  reviewerID   asin                                         reviewText  \\\n",
       "0   0       82947  37386  I REALLY wanted this series but I am in SHOCK ...   \n",
       "1   1       10154  23543  I have to say that this is a work of art for m...   \n",
       "2   2        5789   5724  Alien 3 is certainly the most controversal fil...   \n",
       "3   3        9198   5909  I love this film...preachy?  Well, of course i...   \n",
       "4   4       33252  21214  Even though I previously bought the Gamera Dou...   \n",
       "\n",
       "   overall  \n",
       "0      1.0  \n",
       "1      4.0  \n",
       "2      3.0  \n",
       "3      5.0  \n",
       "4      5.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "商品、用户集合在训练集和测试集的关系："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(set(raw_test_df.reviewerID.unique()).issubset(set(raw_train_df.reviewerID.unique())))\n",
    "print(set(raw_test_df.asin.unique()).issubset(set(raw_train_df.asin.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，测试集的用户、商品是训练集的子集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['reviewerID', 'asin', 'reviewText', 'overall', 'label']\n",
    "raw_test_df['label'] = -1\n",
    "df = pd.concat([raw_train_df[cols], raw_test_df[cols]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 68247 entries, 0 to 11207\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   reviewerID  68247 non-null  int64  \n",
      " 1   asin        68247 non-null  int64  \n",
      " 2   reviewText  68247 non-null  object \n",
      " 3   overall     68247 non-null  float64\n",
      " 4   label       68247 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 共68247条记录，其中训练集57039条，测试集11208条\n",
    "* 不存在缺失记录\n",
    "* 文本特征：reviewText，数值特征：reviewID, asin, overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* reviewerID：用户 ID\n",
    "* asin：商品 ID\n",
    "* reviewText：英文评论文本\n",
    "* overall：用户对商品的打分（1-5）\n",
    "* label：评论质量的 label，1 表示高质量，0 表示低质量（只在训练集出现）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用户ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5758"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.label!=-1].reviewerID.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "商品ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22465"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.label!=-1].asin.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户、商品count特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_feat(df: pd.DataFrame, feats: list):\n",
    "    for feat in feats:\n",
    "        series = df[df.label!=-1][feat].value_counts()\n",
    "        tmp_df = pd.DataFrame({\n",
    "            feat:series.index,\n",
    "            feat + '_count': series.values\n",
    "        })\n",
    "\n",
    "        df = pd.merge(df, tmp_df, how='left', on=feat)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_feats = ['reviewerID', 'asin']\n",
    "\n",
    "df = count_feat(df, count_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "      <th>reviewerID_count</th>\n",
       "      <th>asin_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7885</td>\n",
       "      <td>3901</td>\n",
       "      <td>First off, allow me to correct a common mistak...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52087</td>\n",
       "      <td>47978</td>\n",
       "      <td>I am really troubled by this Story and Enterta...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5701</td>\n",
       "      <td>3667</td>\n",
       "      <td>A near-perfect film version of a downright glo...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewerID   asin                                         reviewText  \\\n",
       "0        7885   3901  First off, allow me to correct a common mistak...   \n",
       "1       52087  47978  I am really troubled by this Story and Enterta...   \n",
       "2        5701   3667  A near-perfect film version of a downright glo...   \n",
       "\n",
       "   overall  label  reviewerID_count  asin_count  \n",
       "0      5.0      0                33           5  \n",
       "1      3.0      0                 6           4  \n",
       "2      4.0      1                29           1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "商品评分特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    23365\n",
       "4.0    10104\n",
       "1.0     9970\n",
       "3.0     7232\n",
       "2.0     6368\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label!=-1].overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df.label!=-1].overall.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户评分、商品评分交叉特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby('reviewerID')[['overall']].aggregate(['mean', 'min', 'max', 'std'])\n",
    "tmp.columns = ['cross_overall_userid_mean', 'cross_overall_userid_min',\n",
    "               'cross_overall_userid_max', 'cross_overall_userid_std']\n",
    "df = df.merge(tmp, on='reviewerID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_overall_userid_feats = ['cross_overall_userid_mean', 'cross_overall_userid_min',\n",
    "                              'cross_overall_userid_max', 'cross_overall_userid_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby('asin')[['overall']].aggregate(['mean', 'min', 'max', 'std'])\n",
    "tmp.columns = ['cross_overall_asin_mean', 'cross_overall_asin_min',\n",
    "               'cross_overall_asin_max', 'cross_overall_asin_std']\n",
    "tmp.fillna(0, inplace=True)\n",
    "df = df.merge(tmp, on='asin', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_overall_asin_feats = ['cross_overall_asin_mean', 'cross_overall_asin_min',\n",
    "                            'cross_overall_asin_max', 'cross_overall_asin_std']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评论特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [review for review in df.reviewText]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.3 s, sys: 584 ms, total: 21.9 s\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "NGRAM = 2\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_df=0.95, min_df=0.01, ngram_range=(1, NGRAM))\n",
    "review_count_vector = count_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1768\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary size: %d' % len(count_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_count_df = pd.DataFrame(review_count_vector.toarray(),\n",
    "                               columns=['review_' + str(i) for i in range(len(count_vectorizer.vocabulary_))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_feats = list(review_count_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, review_count_df], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df.label!=-1]\n",
    "test_df = df[df.label==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57039, 1783), (11208, 1783))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(itertools.chain(['reviewerID', 'asin', 'overall', 'reviewerID_count', 'asin_count'],\n",
    "                          review_feats, cross_overall_asin_feats, cross_overall_userid_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_df[features], train_df['label'],\n",
    "                                                  test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset X: (45631, 1781), y: (45631,)\n",
      "val   dataset X: (11408, 1781), y: (11408,)\n"
     ]
    }
   ],
   "source": [
    "print('train dataset X: %s, y: %s' % (X_train.shape, y_train.shape))\n",
    "print('val   dataset X: %s, y: %s' % (X_val.shape, y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=2000, max_depth=10, min_samples_leaf=20, random_state=42, \n",
    "                                  n_jobs=12, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=12)]: Done 2000 out of 2000 | elapsed:   39.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=20, n_estimators=2000,\n",
       "                       n_jobs=12, random_state=42, verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 2000 out of 2000 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_model.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11408,), (11408,))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8092325750124508"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Namespace(\n",
    "    n_estimators=2000,\n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=20,\n",
    "    verbose=1,\n",
    "    n_jobs=12,\n",
    "    learning_rate=1e-2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_base_model = DecisionTreeClassifier(max_depth=params.max_depth,\n",
    "                                         min_samples_leaf=params.min_samples_leaf,\n",
    "                                         random_state=params.random_state)\n",
    "\n",
    "tree_bagging_model = BaggingClassifier(base_estimator=tree_base_model,\n",
    "                                       n_estimators=params.n_estimators, \n",
    "                                       random_state=params.random_state,\n",
    "                                       n_jobs=params.n_jobs,\n",
    "                                       verbose=params.verbose)\n",
    "\n",
    "tree_bagging_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   2 out of  12 | elapsed:   55.7s remaining:  4.6min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:   57.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8159884936426698"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tree_bagging_model.predict_proba(X_val)[:,1]\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_base_model = DecisionTreeClassifier(max_depth=params.max_depth,\n",
    "                                         min_samples_leaf=params.min_samples_leaf,\n",
    "                                         random_state=params.random_state)\n",
    "\n",
    "boosting_model = AdaBoostClassifier(tree_base_model,\n",
    "                                    learning_rate=1.0,\n",
    "                                    n_estimators=50,\n",
    "                                    random_state=params.random_state)\n",
    "\n",
    "boosting_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_val, boosting_model.predict_proba(X_val)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 动手实现算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: utf8\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "class MyBaggingClassifier(object):\n",
    "    \"\"\"Bagging classifier.\"\"\"\n",
    "\n",
    "    def __init__(self, base_estimator, n_estimators=100, max_samples=1.0):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, X, y, val_set=None):\n",
    "        self.estimators = []\n",
    "        n_samples = int(len(X) * self.max_samples)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            estimator = copy.deepcopy(self.base_estimator)\n",
    "            seed = np.random.randint(1, 100)\n",
    "            rng = np.random.RandomState(seed)\n",
    "\n",
    "            tm = time.time()\n",
    "            samples = rng.randint(0, n_samples, n_samples)\n",
    "            # for i in range(n_samples):\n",
    "            #     samples.append(rng.choice(n_samples))\n",
    "\n",
    "            X_samples = X[samples]\n",
    "            y_samples = y[samples]\n",
    "            estimator.fit(X_samples, y_samples)\n",
    "\n",
    "            self.estimators.append(estimator)\n",
    "\n",
    "            if val_set:\n",
    "                X_val, y_val = val_set\n",
    "                auc_score = roc_auc_score(y_val, self.predict_proba(X_val)[:, 1])\n",
    "                msg = 'fit %s estimators, auc: %.8f, elapse %.2f seconds, ' % (len(self.estimators),\n",
    "                                                                               auc_score,\n",
    "                                                                               time.time() - tm)\n",
    "            else:\n",
    "                msg = 'fit %s estimators, elapse %.2f seconds ' % (len(self.estimators), time.time() - tm)\n",
    "            print(msg)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        assert len(self.estimators) > 0, 'Please train the model first!'\n",
    "\n",
    "        y_pred = np.zeros((len(X), 2))\n",
    "\n",
    "        for estimator in self.estimators:\n",
    "            y_pred += estimator.predict_proba(X)\n",
    "\n",
    "        return y_pred / len(self.estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bagging Tree Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit 1 estimators, auc: 0.78262241, elapse 19.75 seconds, \n",
      "fit 2 estimators, auc: 0.79233879, elapse 19.04 seconds, \n",
      "fit 3 estimators, auc: 0.79901663, elapse 19.73 seconds, \n",
      "fit 4 estimators, auc: 0.80068500, elapse 19.29 seconds, \n",
      "fit 5 estimators, auc: 0.80454024, elapse 19.36 seconds, \n",
      "fit 6 estimators, auc: 0.80685293, elapse 19.79 seconds, \n",
      "fit 7 estimators, auc: 0.80678350, elapse 19.59 seconds, \n",
      "fit 8 estimators, auc: 0.80804805, elapse 18.97 seconds, \n",
      "fit 9 estimators, auc: 0.80767467, elapse 19.45 seconds, \n",
      "fit 10 estimators, auc: 0.80850144, elapse 19.03 seconds, \n",
      "fit 11 estimators, auc: 0.80932045, elapse 19.50 seconds, \n",
      "fit 12 estimators, auc: 0.80996341, elapse 18.75 seconds, \n",
      "fit 13 estimators, auc: 0.81047112, elapse 19.71 seconds, \n",
      "fit 14 estimators, auc: 0.81081549, elapse 20.11 seconds, \n",
      "fit 15 estimators, auc: 0.81106226, elapse 19.35 seconds, \n",
      "fit 16 estimators, auc: 0.81100454, elapse 20.00 seconds, \n",
      "fit 17 estimators, auc: 0.81032003, elapse 19.39 seconds, \n",
      "fit 18 estimators, auc: 0.81064322, elapse 20.07 seconds, \n",
      "fit 19 estimators, auc: 0.81105785, elapse 21.14 seconds, \n",
      "fit 20 estimators, auc: 0.81137591, elapse 20.07 seconds, \n"
     ]
    }
   ],
   "source": [
    "tree_base_model = DecisionTreeClassifier(max_depth=10,\n",
    "                                         min_samples_leaf=params.min_samples_leaf)\n",
    "\n",
    "my_bagging_tree_model = MyBaggingClassifier(tree_base_model, \n",
    "                                            n_estimators=20,\n",
    "                                            max_samples=1.0)\n",
    "\n",
    "my_bagging_tree_model.fit(X_train.iloc[:,].values, y_train.iloc[:,].values, val_set=(X_val.values, y_val.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8113759114211271"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = my_bagging_tree_model.predict_proba(X_val.values)[:,1]\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: utf8\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "class MyAdaBoostClassifier(object):\n",
    "    \"\"\"Boosting ensemble classififer.\"\"\"\n",
    "\n",
    "    def __init__(self, base_estimator, n_estimators):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators = []\n",
    "        self.estimator_weights = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.estimators = []\n",
    "        self.estimator_weights = []\n",
    "\n",
    "        n_samples = len(X)\n",
    "        sample_weights = np.zeros(n_samples) + 1 / n_samples\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            estimator = copy.deepcopy(self.base_estimator)\n",
    "            estimator.fit(X, y, sample_weight=sample_weights)\n",
    "\n",
    "            y_pred = estimator.predict(X)\n",
    "\n",
    "            # calculate error rate\n",
    "            err_rate = np.sum(sample_weights[y != y_pred])\n",
    "            if err_rate > 0.5:\n",
    "                print('error rate %.4f, break' % err_rate)\n",
    "                break\n",
    "\n",
    "            # update sample weights\n",
    "            beta = err_rate / (1 - err_rate)\n",
    "            sample_weights[y_pred == y] *= beta   # correct classification\n",
    "\n",
    "            # normalize sample weights\n",
    "            sample_weights /= np.sum(sample_weights)\n",
    "\n",
    "            self.estimator_weights.append(np.log(1/beta))\n",
    "            self.estimators.append(estimator)\n",
    "\n",
    "            print('fit %s estimators, error rate: %.6f, log(1/beta): %.6f' % (i, err_rate, np.log(1/beta)))\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        assert len(self.estimators) > 0, 'Please train the model first!'\n",
    "\n",
    "        y_pred = np.zeros((len(X), 2))\n",
    "        for i, estimator in enumerate(self.estimators):\n",
    "            y_pred += (estimator.predict_proba(X) * self.estimator_weights[i])\n",
    "\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boosting Tree Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit 0 estimators, error rate: 0.221187, log(1/beta): 1.258760\n",
      "fit 1 estimators, error rate: 0.276885, log(1/beta): 0.959965\n",
      "fit 2 estimators, error rate: 0.370347, log(1/beta): 0.530730\n",
      "fit 3 estimators, error rate: 0.427773, log(1/beta): 0.290944\n",
      "fit 4 estimators, error rate: 0.414089, log(1/beta): 0.347086\n",
      "fit 5 estimators, error rate: 0.437651, log(1/beta): 0.250702\n",
      "fit 6 estimators, error rate: 0.440181, log(1/beta): 0.240429\n",
      "fit 7 estimators, error rate: 0.450307, log(1/beta): 0.199429\n",
      "fit 8 estimators, error rate: 0.463145, log(1/beta): 0.147687\n",
      "fit 9 estimators, error rate: 0.463569, log(1/beta): 0.145983\n",
      "fit 10 estimators, error rate: 0.463300, log(1/beta): 0.147066\n",
      "fit 11 estimators, error rate: 0.478944, log(1/beta): 0.084273\n",
      "fit 12 estimators, error rate: 0.477414, log(1/beta): 0.090406\n",
      "fit 13 estimators, error rate: 0.476198, log(1/beta): 0.095278\n",
      "fit 14 estimators, error rate: 0.457666, log(1/beta): 0.169743\n",
      "fit 15 estimators, error rate: 0.463139, log(1/beta): 0.147710\n",
      "fit 16 estimators, error rate: 0.478681, log(1/beta): 0.085327\n",
      "fit 17 estimators, error rate: 0.477429, log(1/beta): 0.090347\n",
      "fit 18 estimators, error rate: 0.475270, log(1/beta): 0.099000\n",
      "fit 19 estimators, error rate: 0.480627, log(1/beta): 0.077533\n",
      "fit 20 estimators, error rate: 0.489676, log(1/beta): 0.041304\n",
      "fit 21 estimators, error rate: 0.492926, log(1/beta): 0.028299\n",
      "fit 22 estimators, error rate: 0.487482, log(1/beta): 0.050083\n",
      "fit 23 estimators, error rate: 0.488872, log(1/beta): 0.044521\n",
      "fit 24 estimators, error rate: 0.487001, log(1/beta): 0.052006\n",
      "fit 25 estimators, error rate: 0.445456, log(1/beta): 0.219048\n",
      "fit 26 estimators, error rate: 0.470222, log(1/beta): 0.119254\n",
      "fit 27 estimators, error rate: 0.491389, log(1/beta): 0.034449\n",
      "fit 28 estimators, error rate: 0.483533, log(1/beta): 0.065892\n",
      "fit 29 estimators, error rate: 0.493108, log(1/beta): 0.027569\n",
      "fit 30 estimators, error rate: 0.489843, log(1/beta): 0.040633\n",
      "fit 31 estimators, error rate: 0.484556, log(1/beta): 0.061794\n",
      "fit 32 estimators, error rate: 0.488999, log(1/beta): 0.044010\n",
      "fit 33 estimators, error rate: 0.493389, log(1/beta): 0.026444\n",
      "fit 34 estimators, error rate: 0.491936, log(1/beta): 0.032257\n",
      "fit 35 estimators, error rate: 0.492610, log(1/beta): 0.029560\n",
      "fit 36 estimators, error rate: 0.493150, log(1/beta): 0.027403\n",
      "fit 37 estimators, error rate: 0.493332, log(1/beta): 0.026674\n",
      "fit 38 estimators, error rate: 0.495531, log(1/beta): 0.017876\n",
      "fit 39 estimators, error rate: 0.493476, log(1/beta): 0.026098\n",
      "fit 40 estimators, error rate: 0.492184, log(1/beta): 0.031267\n",
      "fit 41 estimators, error rate: 0.494341, log(1/beta): 0.022638\n",
      "fit 42 estimators, error rate: 0.486962, log(1/beta): 0.052164\n",
      "fit 43 estimators, error rate: 0.489239, log(1/beta): 0.043050\n",
      "fit 44 estimators, error rate: 0.482677, log(1/beta): 0.069318\n",
      "fit 45 estimators, error rate: 0.482438, log(1/beta): 0.070278\n",
      "fit 46 estimators, error rate: 0.493134, log(1/beta): 0.027466\n",
      "fit 47 estimators, error rate: 0.492988, log(1/beta): 0.028048\n",
      "fit 48 estimators, error rate: 0.487881, log(1/beta): 0.048486\n",
      "fit 49 estimators, error rate: 0.488198, log(1/beta): 0.047218\n",
      "fit 50 estimators, error rate: 0.479959, log(1/beta): 0.080207\n",
      "fit 51 estimators, error rate: 0.482886, log(1/beta): 0.068483\n",
      "fit 52 estimators, error rate: 0.483410, log(1/beta): 0.066383\n",
      "fit 53 estimators, error rate: 0.471102, log(1/beta): 0.115721\n",
      "fit 54 estimators, error rate: 0.477070, log(1/beta): 0.091786\n",
      "fit 55 estimators, error rate: 0.474119, log(1/beta): 0.103615\n",
      "fit 56 estimators, error rate: 0.466594, log(1/beta): 0.133825\n",
      "fit 57 estimators, error rate: 0.481970, log(1/beta): 0.072152\n",
      "fit 58 estimators, error rate: 0.488672, log(1/beta): 0.045319\n",
      "fit 59 estimators, error rate: 0.483244, log(1/beta): 0.067048\n",
      "fit 60 estimators, error rate: 0.486820, log(1/beta): 0.052731\n",
      "fit 61 estimators, error rate: 0.482105, log(1/beta): 0.071609\n",
      "fit 62 estimators, error rate: 0.483931, log(1/beta): 0.064297\n",
      "fit 63 estimators, error rate: 0.491298, log(1/beta): 0.034810\n",
      "fit 64 estimators, error rate: 0.488581, log(1/beta): 0.045684\n",
      "fit 65 estimators, error rate: 0.477298, log(1/beta): 0.090870\n",
      "fit 66 estimators, error rate: 0.483896, log(1/beta): 0.064438\n",
      "fit 67 estimators, error rate: 0.488455, log(1/beta): 0.046188\n",
      "fit 68 estimators, error rate: 0.488869, log(1/beta): 0.044531\n",
      "fit 69 estimators, error rate: 0.490159, log(1/beta): 0.039369\n",
      "fit 70 estimators, error rate: 0.494086, log(1/beta): 0.023656\n",
      "fit 71 estimators, error rate: 0.494713, log(1/beta): 0.021150\n",
      "fit 72 estimators, error rate: 0.488939, log(1/beta): 0.044249\n",
      "fit 73 estimators, error rate: 0.493833, log(1/beta): 0.024668\n",
      "fit 74 estimators, error rate: 0.486736, log(1/beta): 0.053070\n",
      "fit 75 estimators, error rate: 0.487977, log(1/beta): 0.048103\n",
      "fit 76 estimators, error rate: 0.493326, log(1/beta): 0.026697\n",
      "fit 77 estimators, error rate: 0.491943, log(1/beta): 0.032230\n",
      "fit 78 estimators, error rate: 0.490839, log(1/beta): 0.036650\n",
      "fit 79 estimators, error rate: 0.491683, log(1/beta): 0.033272\n",
      "fit 80 estimators, error rate: 0.491148, log(1/beta): 0.035413\n",
      "fit 81 estimators, error rate: 0.489477, log(1/beta): 0.042100\n",
      "fit 82 estimators, error rate: 0.493883, log(1/beta): 0.024469\n",
      "fit 83 estimators, error rate: 0.497879, log(1/beta): 0.008484\n",
      "fit 84 estimators, error rate: 0.495948, log(1/beta): 0.016207\n",
      "fit 85 estimators, error rate: 0.495988, log(1/beta): 0.016048\n",
      "fit 86 estimators, error rate: 0.495555, log(1/beta): 0.017782\n",
      "fit 87 estimators, error rate: 0.496317, log(1/beta): 0.014731\n",
      "fit 88 estimators, error rate: 0.496955, log(1/beta): 0.012178\n",
      "fit 89 estimators, error rate: 0.498041, log(1/beta): 0.007837\n",
      "fit 90 estimators, error rate: 0.498050, log(1/beta): 0.007798\n",
      "fit 91 estimators, error rate: 0.496529, log(1/beta): 0.013882\n",
      "fit 92 estimators, error rate: 0.496050, log(1/beta): 0.015800\n",
      "fit 93 estimators, error rate: 0.493374, log(1/beta): 0.026506\n",
      "fit 94 estimators, error rate: 0.493296, log(1/beta): 0.026817\n",
      "fit 95 estimators, error rate: 0.494686, log(1/beta): 0.021257\n",
      "fit 96 estimators, error rate: 0.483036, log(1/beta): 0.067882\n",
      "fit 97 estimators, error rate: 0.489255, log(1/beta): 0.042988\n",
      "fit 98 estimators, error rate: 0.493552, log(1/beta): 0.025793\n",
      "fit 99 estimators, error rate: 0.494670, log(1/beta): 0.021322\n"
     ]
    }
   ],
   "source": [
    "tree_base_model = DecisionTreeClassifier(max_depth=3,\n",
    "                                         min_samples_leaf=params.min_samples_leaf,\n",
    "                                         random_state=42)\n",
    "\n",
    "my_boosting_tree_model = MyAdaBoostClassifier(tree_base_model, n_estimators=100)\n",
    "\n",
    "my_boosting_tree_model.fit(X_train.iloc[:,].values, y_train.iloc[:,].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8005359865074025"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, my_boosting_tree_model.predict_proba(X_val.values)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提交数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = my_bagging_tree_model.predict_proba(test_df[features].values)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\n",
    "    'Id': raw_test_df.Id,\n",
    "    'Predicted': y_pred,\n",
    "})\n",
    "\n",
    "result.to_csv('results/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
